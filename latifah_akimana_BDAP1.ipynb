{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bff3c76",
   "metadata": {},
   "source": [
    "# **AFRICAN INSTITUTE FOR MATHEMATICAL SCIENCE - RWANDA**\n",
    "\n",
    "---\n",
    "# **Big Data Analytics with Python**\n",
    "## Assignment 1\n",
    "## Name: Latifah AKIMANA\n",
    "### <span style=\"color:red\">Note: all datasets where shared in the classroom</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd3de03",
   "metadata": {},
   "source": [
    "# **Part 1: Reading, Writing and Validating Data in PySpark HW**\n",
    "\n",
    "Welcome to your first coding homework assignment in PySpark! I hope you enjoyed the lecture on Reading, Writing and Validating dataframes. Now it's time to put what you've learned into action! \n",
    "\n",
    "I've included several instructions below to help guide you through this homework assignment which I hope will get you feeling even comfortable reading, writing and validating dataframes. If you get stuck at any point, feel free to jump to the next lecture where I will guide you through my solutions to the HW assignment. \n",
    "\n",
    "Have fun!\n",
    "\n",
    "Let's dig right in!\n",
    "\n",
    "\n",
    "## But first things first.....\n",
    "We need to always begin every Spark session by creating a Spark instance. Let's go ahead and use the method we learned in the lecture in the cell below. Also see if you can remember how to open the Spark UI (using a link that automatically guides you there). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "daa26513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b33951f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.0.1)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyspark) (0.10.9.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8726acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/18 15:53:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/11/18 15:53:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.6.254.236:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Assignment1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1166a7620>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Assignment1\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbd40ea",
   "metadata": {},
   "source": [
    "## Next let's start by reading a basic csv dataset\n",
    "\n",
    "Download the pga_tour_historical dataset that is attached to this lecture and save it whatever folder you want, then read it in. \n",
    "\n",
    "**Data Source:** https://www.kaggle.com/bradklassen/pga-tour-20102018-data\n",
    "\n",
    "Rememer to try letting Spark infer the header and infer the Schema types!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "890e03ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "historical_dataframe = spark.read.csv('Datasets/pga_tour_historical.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b793eb29",
   "metadata": {},
   "source": [
    "## 1. View first 5 lines of dataframe\n",
    "First generate a view of the first 5 lines of the dataframe to get an idea of what is inside. We went over two ways of doing this... see if you can remember BOTH ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93f44709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+----------------+--------------------+-----+\n",
      "|    Player Name|Season|       Statistic|            Variable|Value|\n",
      "+---------------+------+----------------+--------------------+-----+\n",
      "|Robert Garrigus|  2010|Driving Distance|Driving Distance ...|   71|\n",
      "|   Bubba Watson|  2010|Driving Distance|Driving Distance ...|   77|\n",
      "| Dustin Johnson|  2010|Driving Distance|Driving Distance ...|   83|\n",
      "|Brett Wetterich|  2010|Driving Distance|Driving Distance ...|   54|\n",
      "|    J.B. Holmes|  2010|Driving Distance|Driving Distance ...|  100|\n",
      "+---------------+------+----------------+--------------------+-----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "historical_dataframe.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c875fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Season</th>\n",
       "      <th>Statistic</th>\n",
       "      <th>Variable</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robert Garrigus</td>\n",
       "      <td>2010</td>\n",
       "      <td>Driving Distance</td>\n",
       "      <td>Driving Distance - (ROUNDS)</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>2010</td>\n",
       "      <td>Driving Distance</td>\n",
       "      <td>Driving Distance - (ROUNDS)</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dustin Johnson</td>\n",
       "      <td>2010</td>\n",
       "      <td>Driving Distance</td>\n",
       "      <td>Driving Distance - (ROUNDS)</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brett Wetterich</td>\n",
       "      <td>2010</td>\n",
       "      <td>Driving Distance</td>\n",
       "      <td>Driving Distance - (ROUNDS)</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J.B. Holmes</td>\n",
       "      <td>2010</td>\n",
       "      <td>Driving Distance</td>\n",
       "      <td>Driving Distance - (ROUNDS)</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Player Name  Season         Statistic                     Variable  \\\n",
       "0  Robert Garrigus    2010  Driving Distance  Driving Distance - (ROUNDS)   \n",
       "1     Bubba Watson    2010  Driving Distance  Driving Distance - (ROUNDS)   \n",
       "2   Dustin Johnson    2010  Driving Distance  Driving Distance - (ROUNDS)   \n",
       "3  Brett Wetterich    2010  Driving Distance  Driving Distance - (ROUNDS)   \n",
       "4      J.B. Holmes    2010  Driving Distance  Driving Distance - (ROUNDS)   \n",
       "\n",
       "  Value  \n",
       "0    71  \n",
       "1    77  \n",
       "2    83  \n",
       "3    54  \n",
       "4   100  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another way\n",
    "historical_dataframe.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3889d6e6",
   "metadata": {},
   "source": [
    "## 2. Print the schema details\n",
    "\n",
    "Now print the details of the dataframes schema that Spark infered to ensure that it was infered correctly. Sometimes it is not infered correctly, so we need to watch out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2bde96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Player Name: string (nullable = true)\n",
      " |-- Season: integer (nullable = true)\n",
      " |-- Statistic: string (nullable = true)\n",
      " |-- Variable: string (nullable = true)\n",
      " |-- Value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "historical_dataframe.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dac547",
   "metadata": {},
   "source": [
    "## 3. Edit the schema during the read in\n",
    "\n",
    "We can see from the output above that Spark did not correctly infer that the \"value\" column was an integer value. Let's try specifying the schema this time to let spark know what the schema should be.\n",
    "\n",
    "Here is a link to see a list of PySpark data types in case you need it (also attached to the lecture): \n",
    "https://spark.apache.org/docs/latest/sql-ref-datatypes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a266befe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringType()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_dataframe.schema['Value'].dataType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ec9ff",
   "metadata": {},
   "source": [
    "## 4. Generate summary statistics for only one variable\n",
    "\n",
    "See if you can generate summary statistics for only the \"Value\" column using the .describe function\n",
    "\n",
    "(count, mean, stddev, min, max) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bf29bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:==============>                                            (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             Value|\n",
      "+-------+------------------+\n",
      "|  count|           2696905|\n",
      "|   mean|137053.96543856172|\n",
      "| stddev| 6046342.246458627|\n",
      "|    min|        $1,001,580|\n",
      "|    max|   the Memorial/Mu|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "historical_dataframe.describe(['Value']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e84a8b",
   "metadata": {},
   "source": [
    "## 5. Generate summary statistics for TWO variables\n",
    "Now try to generate ONLY the count min and max for BOTH the \"Value\" and \"Season\" variable using the select. You can't use the .describe function for this one but see if you can remember which function you CAN use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b5175fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-------+\n",
      "|summary|          Value| Season|\n",
      "+-------+---------------+-------+\n",
      "|  count|        2696905|2740403|\n",
      "|    min|     $1,001,580|   2010|\n",
      "|    max|the Memorial/Mu|   2018|\n",
      "+-------+---------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "historical_dataframe.select(\"Value\", \"Season\").summary(\"count\", \"min\", \"max\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca8bf01",
   "metadata": {},
   "source": [
    "## 6. Write a parquet file\n",
    "\n",
    "Now try writing a parquet file (not partitioned) from the pga dataset. But first create a new dataframe containing ONLY the the \"Season\" and \"Value\" fields (using the \"select command you used in the question above) and write a parquet file partitioned by \"Season\". This is a bit of a challenge aimed at getting you ready for material that will be covered later on in the course. Don't feel bad if you can't figure it out.\n",
    "\n",
    "*Note that if any of your variable names contain spaces, spark will produce an error message with this call. That is why we are selecting ONLY the \"Season\" and \"Value\" fields. Ideally we should renamed those columns but we haven't gotten to that yet in this course but we will soon!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1eca0ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/15 20:09:29 WARN TaskSetManager: Stage 13 contains a task of very large size (7605 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "values = historical_dataframe.select(\"Value\", \"Season\").collect()\n",
    "data_frame = spark.createDataFrame(values)\n",
    "# Writing a parquete file \n",
    "data_frame.write.mode('overwrite').parquet('parquet_not_partitioned')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32862f51",
   "metadata": {},
   "source": [
    "## 7. Write a partioned parquet file\n",
    "\n",
    "You will need to use the same limited dataframe that you created in the previous question to accomplish this task as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d803f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/15 14:12:05 WARN TaskSetManager: Stage 12 contains a task of very large size (7605 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Writing a parquet file partitioned by Season\n",
    "data_frame.write.mode('overwrite').partitionBy('Season').parquet(\"parquet_partitioned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f935d61",
   "metadata": {},
   "source": [
    "## 8. Read in a partitioned parquet file\n",
    "\n",
    "Now try reading in the partitioned parquet file you just created above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4135a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Value: string, Season: int]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitioned=spark.read.parquet('partitioned')\n",
    "partitioned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8b5b1d",
   "metadata": {},
   "source": [
    "## 9. Reading in a set of paritioned parquet files\n",
    "\n",
    "Now try only reading Seasons 2010, 2011 and 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5dda5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|Value|Season|\n",
      "+-----+------+\n",
      "|   71|  2010|\n",
      "|   77|  2010|\n",
      "|   83|  2010|\n",
      "|   54|  2010|\n",
      "|  100|  2010|\n",
      "|   63|  2010|\n",
      "|   88|  2010|\n",
      "|   64|  2010|\n",
      "|   64|  2010|\n",
      "|   92|  2010|\n",
      "|   75|  2010|\n",
      "|   54|  2010|\n",
      "|   76|  2010|\n",
      "|   94|  2010|\n",
      "|   82|  2010|\n",
      "|   85|  2010|\n",
      "|   79|  2010|\n",
      "|   89|  2010|\n",
      "|   88|  2010|\n",
      "|   91|  2010|\n",
      "|   91|  2010|\n",
      "|   84|  2010|\n",
      "|   54|  2010|\n",
      "|   73|  2010|\n",
      "|   74|  2010|\n",
      "|   84|  2010|\n",
      "|   75|  2010|\n",
      "|   88|  2010|\n",
      "|   53|  2010|\n",
      "|   81|  2010|\n",
      "|   87|  2010|\n",
      "|   55|  2010|\n",
      "|   70|  2010|\n",
      "|  103|  2010|\n",
      "|   64|  2010|\n",
      "|   91|  2010|\n",
      "|   81|  2010|\n",
      "|   73|  2010|\n",
      "|   78|  2010|\n",
      "|   61|  2010|\n",
      "|   79|  2010|\n",
      "|   87|  2010|\n",
      "|   89|  2010|\n",
      "|  101|  2010|\n",
      "|   82|  2010|\n",
      "|   92|  2010|\n",
      "|   98|  2010|\n",
      "|   58|  2010|\n",
      "|   84|  2010|\n",
      "|   66|  2010|\n",
      "+-----+------+\n",
      "only showing top 50 rows\n"
     ]
    }
   ],
   "source": [
    "#path=\"Database\"\n",
    "#users1_2 = spark.read.option(\"basePath\", path).parquet(path+'users1.parquet', path+'users2.parquet')\n",
    "parquet_files = partitioned.filter(partitioned.Season.isin(2010,2011,2012))\n",
    "parquet_files.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aded1d",
   "metadata": {},
   "source": [
    "## 10. Create your own dataframe\n",
    "\n",
    "Try creating your own dataframe below using PySparks *.createDataFrame* function. See if you can make one that contains 4 variables and at least 3 rows. \n",
    "\n",
    "Let's see how creative you can get on the content of the dataframe :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f9fb284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-------+---------------+\n",
      "|   Name|Age|Country|     Occupation|\n",
      "+-------+---+-------+---------------+\n",
      "|Latifah| 25| Rwanda|       Engineer|\n",
      "|  Winny| 29|  Kenya|         Doctor|\n",
      "|  Allen| 28| Rwanda|         Artist|\n",
      "|    Ken| 35| uganda|       Designer|\n",
      "|  Simon| 30|Nigeria|Project Manager|\n",
      "+-------+---+-------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data =[(\"Latifah\", 25,\"Rwanda\",\"Engineer\"),\n",
    "       (\"Winny\", 29,\"Kenya\",\"Doctor\"),\n",
    "       (\"Allen\", 28,\"Rwanda\",\"Artist\"),\n",
    "       (\"Ken\", 35,\"uganda\",\"Designer\"),\n",
    "       (\"Simon\", 30,\"Nigeria\",\"Project Manager\"),\n",
    "]\n",
    "df = spark.createDataFrame(data, [\"Name\", \"Age\", \"Country\", \"Occupation\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9af36bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d6a82",
   "metadata": {},
   "source": [
    "# **Part 2: Manipulating Data in DataFrames HW**\n",
    "\n",
    "\n",
    "#### Let's get started applying what we learned in the lecure!\n",
    "\n",
    "I've provided several questions below to help test and expand you knowledge from the code along lecture. So let's see what you've got!\n",
    "\n",
    "First create your spark instance as we need to do at the start of every project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b9659b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.6.254.236:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Part2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x17d592210>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Part2\").getOrCreate()\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ab0d94",
   "metadata": {},
   "source": [
    "## Read in our Republican vs. Democrats Tweet DataFrame\n",
    "\n",
    "Attached to the lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e8d2a736",
   "metadata": {},
   "outputs": [],
   "source": [
    "repub_demo_df = spark.read.csv('Datasets/Rep_vs_Dem_tweets.csv', inferSchema=True, header=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c93234",
   "metadata": {},
   "source": [
    "## About this dataframe\n",
    "\n",
    "Extracted tweets from all of the representatives (latest 200 as of May 17th 2018)\n",
    "\n",
    "**Source:** https://www.kaggle.com/kapastor/democratvsrepublicantweets#ExtractedTweets.csv\n",
    "\n",
    "Use either .show() or .toPandas() check out the first view rows of the dataframe to get an idea of what we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6daa4f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Congress has allocated about $18‚Ä¶\"</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92484</th>\n",
       "      <td>Republican</td>\n",
       "      <td>RepTomPrice</td>\n",
       "      <td>Check out my op-ed on need for End Executive O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92485</th>\n",
       "      <td>Republican</td>\n",
       "      <td>RepTomPrice</td>\n",
       "      <td>Yesterday, Betty &amp;amp; I had a great time lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92486</th>\n",
       "      <td>Republican</td>\n",
       "      <td>RepTomPrice</td>\n",
       "      <td>We are forever grateful for the service and sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92487</th>\n",
       "      <td>Republican</td>\n",
       "      <td>RepTomPrice</td>\n",
       "      <td>Happy first day of school @CobbSchools! #CobbB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92488</th>\n",
       "      <td>Republican</td>\n",
       "      <td>RepTomPrice</td>\n",
       "      <td>#Zika fears realized in Florida. House GOP act...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92489 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Party         Handle  \\\n",
       "0                                Democrat  RepDarrenSoto   \n",
       "1                                Democrat  RepDarrenSoto   \n",
       "2                                Democrat  RepDarrenSoto   \n",
       "3      Congress has allocated about $18‚Ä¶\"           None   \n",
       "4                                Democrat  RepDarrenSoto   \n",
       "...                                   ...            ...   \n",
       "92484                          Republican    RepTomPrice   \n",
       "92485                          Republican    RepTomPrice   \n",
       "92486                          Republican    RepTomPrice   \n",
       "92487                          Republican    RepTomPrice   \n",
       "92488                          Republican    RepTomPrice   \n",
       "\n",
       "                                                   Tweet  \n",
       "0      Today, Senate Dems vote to #SaveTheInternet. P...  \n",
       "1      RT @WinterHavenSun: Winter Haven resident / Al...  \n",
       "2      RT @NBCLatino: .@RepDarrenSoto noted that Hurr...  \n",
       "3                                                   None  \n",
       "4      RT @NALCABPolicy: Meeting with @RepDarrenSoto ...  \n",
       "...                                                  ...  \n",
       "92484  Check out my op-ed on need for End Executive O...  \n",
       "92485  Yesterday, Betty &amp; I had a great time lear...  \n",
       "92486  We are forever grateful for the service and sa...  \n",
       "92487  Happy first day of school @CobbSchools! #CobbB...  \n",
       "92488  #Zika fears realized in Florida. House GOP act...  \n",
       "\n",
       "[92489 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repub_demo_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "37c93031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+\n",
      "|               Party|       Handle|               Tweet|\n",
      "+--------------------+-------------+--------------------+\n",
      "|            Democrat|RepDarrenSoto|Today, Senate Dem...|\n",
      "|            Democrat|RepDarrenSoto|RT @WinterHavenSu...|\n",
      "|            Democrat|RepDarrenSoto|RT @NBCLatino: .@...|\n",
      "|Congress has allo...|         NULL|                NULL|\n",
      "|            Democrat|RepDarrenSoto|RT @NALCABPolicy:...|\n",
      "|            Democrat|RepDarrenSoto|RT @Vegalteno: Hu...|\n",
      "|            Democrat|RepDarrenSoto|RT @EmgageActionF...|\n",
      "|            Democrat|RepDarrenSoto|Hurricane Maria l...|\n",
      "|            Democrat|RepDarrenSoto|RT @Tharryry: I a...|\n",
      "|            Democrat|RepDarrenSoto|RT @HispanicCaucu...|\n",
      "|            Democrat|RepDarrenSoto|RT @RepStephMurph...|\n",
      "|            Democrat|RepDarrenSoto|RT @AllSaints_FL:...|\n",
      "|            Democrat|RepDarrenSoto|.@realDonaldTrump...|\n",
      "|            Democrat|RepDarrenSoto|Thank you to my m...|\n",
      "|            Democrat|RepDarrenSoto|We paid our respe...|\n",
      "|Sgt Sam Howard - ...|         NULL|                NULL|\n",
      "|            Democrat|RepDarrenSoto|RT @WinterHavenSu...|\n",
      "|            Democrat|RepDarrenSoto|Meet 12 incredibl...|\n",
      "|            Democrat|RepDarrenSoto|RT @wildlifeactio...|\n",
      "|            Democrat|RepDarrenSoto|RT @CHeathWFTV: K...|\n",
      "+--------------------+-------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "repub_demo_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f922b14",
   "metadata": {},
   "source": [
    "**Prevent Truncation of view**\n",
    "\n",
    "If the view you produced above truncated some of the longer tweets, see if you can prevent that so you can read the whole tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7e7e9924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Party                                               |Handle       |Tweet                                                                                                                                       |\n",
      "+----------------------------------------------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Democrat                                            |RepDarrenSoto|Today, Senate Dems vote to #SaveTheInternet. Proud to support similar #NetNeutrality legislation here in the House‚Ä¶ https://t.co/n3tggDLU1L |\n",
      "|Democrat                                            |RepDarrenSoto|RT @WinterHavenSun: Winter Haven resident / Alta Vista teacher is one of several recognized by @RepDarrenSoto for National Teacher Apprecia‚Ä¶|\n",
      "|Democrat                                            |RepDarrenSoto|RT @NBCLatino: .@RepDarrenSoto noted that Hurricane Maria has left approximately $90 billion in damages.                                    |\n",
      "|Congress has allocated about $18‚Ä¶\"                  |NULL         |NULL                                                                                                                                        |\n",
      "|Democrat                                            |RepDarrenSoto|RT @NALCABPolicy: Meeting with @RepDarrenSoto . Thanks for taking the time to meet with @LatinoLeader ED Marucci Guzman. #NALCABPolicy2018.‚Ä¶|\n",
      "|Democrat                                            |RepDarrenSoto|RT @Vegalteno: Hurricane season starts on June 1st; Puerto Rico‚Äôs readiness...well ü§¶üèº‚Äç‚ôÇÔ∏èüò°üò©@Pwr4PuertoRico @RepDarrenSoto @EspaillatNY   |\n",
      "|Democrat                                            |RepDarrenSoto|RT @EmgageActionFL: Thank you to all who came out to our Orlando gala! It was a successful night that would not have been possible without‚Ä¶ |\n",
      "|Democrat                                            |RepDarrenSoto|Hurricane Maria left approx $90 billion in damages, yet only $1 billion was allocated for rebuilding grid. No surpr‚Ä¶ https://t.co/2kU8BcKwUh|\n",
      "|Democrat                                            |RepDarrenSoto|RT @Tharryry: I am delighted that @RepDarrenSoto will be voting for the CRA to overrule the FCC and save our #NetNeutrality rules. Find out‚Ä¶|\n",
      "|Democrat                                            |RepDarrenSoto|RT @HispanicCaucus: Trump's anti-immigrant policies are hurting small businesses across the country that can‚Äôt find Americans willing to do‚Ä¶|\n",
      "|Democrat                                            |RepDarrenSoto|RT @RepStephMurphy: Great joining @WeAreUnidosUS and @RepDarrenSoto for a roundtable in #Orlando on federal issues affecting central Florid‚Ä¶|\n",
      "|Democrat                                            |RepDarrenSoto|RT @AllSaints_FL: Zhihan (John)'s art received awards at this year's state competitions. We just found out he's won the Congressional Distr‚Ä¶|\n",
      "|Democrat                                            |RepDarrenSoto|.@realDonaldTrump official policy to separate immigrant children from their mothers is definition of cruelty‚Ä¶ https://t.co/jCrURA4oLz       |\n",
      "|Democrat                                            |RepDarrenSoto|Thank you to my mom Jean and all the mothers across this nation! You are raising our future. Have a‚Ä¶ https://t.co/MXES0r31VH                |\n",
      "|Democrat                                            |RepDarrenSoto|We paid our respects at Nat‚Äôl Law Enforcement Officers Memorial today for those we lost:                                                    |\n",
      "|Sgt Sam Howard - Kissimmee‚Ä¶ https://t.co/UzPxIVBMYW\"|NULL         |NULL                                                                                                                                        |\n",
      "|Democrat                                            |RepDarrenSoto|RT @WinterHavenSun: Congratulations to  @AHSbloodhounds senior Abygayle Rausch for starting her service to the country at the US Naval Acad‚Ä¶|\n",
      "|Democrat                                            |RepDarrenSoto|Meet 12 incredible young leaders appointed to US Military Academies from our District! @HispanicCaucus‚Ä¶ https://t.co/lND3zgvJ55             |\n",
      "|Democrat                                            |RepDarrenSoto|RT @wildlifeaction: With 1/3 of US wildlife in decline, Florida species like the snowy plover need advocates! As co-sponsors for the Recove‚Ä¶|\n",
      "|Democrat                                            |RepDarrenSoto|RT @CHeathWFTV: Keeping guns out of the wrong hands: following @WFTV report, @RepDarrenSoto asks ATF to look into so-called ghost guns (fir‚Ä¶|\n",
      "+----------------------------------------------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "repub_demo_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f503b75f",
   "metadata": {},
   "source": [
    "**Print Schema**\n",
    "\n",
    "First, check the schema to make sure the datatypes are accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3c4ad346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Party: string (nullable = true)\n",
      " |-- Handle: string (nullable = true)\n",
      " |-- Tweet: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "repub_demo_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae9fb2c",
   "metadata": {},
   "source": [
    "## 1. Can you identify any tweet that mentions the handle @LatinoLeader using regexp_extract?\n",
    "\n",
    "It doesn't matter how you identify the row, any identifier will do. You can test your script on row 5 from this dataset. That row contains @LatinoLeader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6489094b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------+-------------+-------------+\n",
      "|Party                                               |Handle       |Tweet        |\n",
      "+----------------------------------------------------+-------------+-------------+\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "|Congress has allocated about $18‚Ä¶\"                  |NULL         |NULL         |\n",
      "|Democrat                                            |RepDarrenSoto|@LatinoLeader|\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "|Sgt Sam Howard - Kissimmee‚Ä¶ https://t.co/UzPxIVBMYW\"|NULL         |NULL         |\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "|Democrat                                            |RepDarrenSoto|             |\n",
      "+----------------------------------------------------+-------------+-------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "pattern = r\"@LatinoLeader\"\n",
    "df_with_pattern = repub_demo_df.withColumn(\"Tweet\", regexp_extract(\"Tweet\", pattern, 0))\n",
    "df_with_pattern.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc93b9f0",
   "metadata": {},
   "source": [
    "## 2. Replace any value other than 'Democrate' or 'Republican' with 'Other' in the Party column.\n",
    "\n",
    "We can see from the output below, that there are several other values other than 'Democrate' or 'Republican' in the Part column. We are assuming that this is dirty data that needs to be cleaned up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "926ce09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Party   |Handle       |Tweet                                                                                                                                       |\n",
      "+--------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Democrat|RepDarrenSoto|Today, Senate Dems vote to #SaveTheInternet. Proud to support similar #NetNeutrality legislation here in the House‚Ä¶ https://t.co/n3tggDLU1L |\n",
      "|Democrat|RepDarrenSoto|RT @WinterHavenSun: Winter Haven resident / Alta Vista teacher is one of several recognized by @RepDarrenSoto for National Teacher Apprecia‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @NBCLatino: .@RepDarrenSoto noted that Hurricane Maria has left approximately $90 billion in damages.                                    |\n",
      "|Other   |NULL         |NULL                                                                                                                                        |\n",
      "|Democrat|RepDarrenSoto|RT @NALCABPolicy: Meeting with @RepDarrenSoto . Thanks for taking the time to meet with @LatinoLeader ED Marucci Guzman. #NALCABPolicy2018.‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @Vegalteno: Hurricane season starts on June 1st; Puerto Rico‚Äôs readiness...well ü§¶üèº‚Äç‚ôÇÔ∏èüò°üò©@Pwr4PuertoRico @RepDarrenSoto @EspaillatNY   |\n",
      "|Democrat|RepDarrenSoto|RT @EmgageActionFL: Thank you to all who came out to our Orlando gala! It was a successful night that would not have been possible without‚Ä¶ |\n",
      "|Democrat|RepDarrenSoto|Hurricane Maria left approx $90 billion in damages, yet only $1 billion was allocated for rebuilding grid. No surpr‚Ä¶ https://t.co/2kU8BcKwUh|\n",
      "|Democrat|RepDarrenSoto|RT @Tharryry: I am delighted that @RepDarrenSoto will be voting for the CRA to overrule the FCC and save our #NetNeutrality rules. Find out‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @HispanicCaucus: Trump's anti-immigrant policies are hurting small businesses across the country that can‚Äôt find Americans willing to do‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @RepStephMurphy: Great joining @WeAreUnidosUS and @RepDarrenSoto for a roundtable in #Orlando on federal issues affecting central Florid‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @AllSaints_FL: Zhihan (John)'s art received awards at this year's state competitions. We just found out he's won the Congressional Distr‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|.@realDonaldTrump official policy to separate immigrant children from their mothers is definition of cruelty‚Ä¶ https://t.co/jCrURA4oLz       |\n",
      "|Democrat|RepDarrenSoto|Thank you to my mom Jean and all the mothers across this nation! You are raising our future. Have a‚Ä¶ https://t.co/MXES0r31VH                |\n",
      "|Democrat|RepDarrenSoto|We paid our respects at Nat‚Äôl Law Enforcement Officers Memorial today for those we lost:                                                    |\n",
      "|Other   |NULL         |NULL                                                                                                                                        |\n",
      "|Democrat|RepDarrenSoto|RT @WinterHavenSun: Congratulations to  @AHSbloodhounds senior Abygayle Rausch for starting her service to the country at the US Naval Acad‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|Meet 12 incredible young leaders appointed to US Military Academies from our District! @HispanicCaucus‚Ä¶ https://t.co/lND3zgvJ55             |\n",
      "|Democrat|RepDarrenSoto|RT @wildlifeaction: With 1/3 of US wildlife in decline, Florida species like the snowy plover need advocates! As co-sponsors for the Recove‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @CHeathWFTV: Keeping guns out of the wrong hands: following @WFTV report, @RepDarrenSoto asks ATF to look into so-called ghost guns (fir‚Ä¶|\n",
      "+--------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "repub_demo_df = repub_demo_df.withColumn(\"Party\", when(repub_demo_df.Party==\"Democrat\", 'Democrat').when(repub_demo_df.Party == \"Republican\", \"Republican\").otherwise('Other'))\n",
    "repub_demo_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe61a23",
   "metadata": {},
   "source": [
    "## 3. Delete all embedded links (ie. \"https:....)\n",
    "\n",
    "For example see the first row in the tweets dataframe. \n",
    "\n",
    "*Note: this may require an google search :)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "108664a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Party   |Handle       |Tweet                                                                                                                                       |\n",
      "+--------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Democrat|RepDarrenSoto|Today, Senate Dems vote to #SaveTheInternet. Proud to support similar #NetNeutrality legislation here in the House‚Ä¶                         |\n",
      "|Democrat|RepDarrenSoto|RT @WinterHavenSun: Winter Haven resident / Alta Vista teacher is one of several recognized by @RepDarrenSoto for National Teacher Apprecia‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @NBCLatino: .@RepDarrenSoto noted that Hurricane Maria has left approximately $90 billion in damages.                                    |\n",
      "|Other   |NULL         |NULL                                                                                                                                        |\n",
      "|Democrat|RepDarrenSoto|RT @NALCABPolicy: Meeting with @RepDarrenSoto . Thanks for taking the time to meet with @LatinoLeader ED Marucci Guzman. #NALCABPolicy2018.‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @Vegalteno: Hurricane season starts on June 1st; Puerto Rico‚Äôs readiness...well ü§¶üèº‚Äç‚ôÇÔ∏èüò°üò©@Pwr4PuertoRico @RepDarrenSoto @EspaillatNY   |\n",
      "|Democrat|RepDarrenSoto|RT @EmgageActionFL: Thank you to all who came out to our Orlando gala! It was a successful night that would not have been possible without‚Ä¶ |\n",
      "|Democrat|RepDarrenSoto|Hurricane Maria left approx $90 billion in damages, yet only $1 billion was allocated for rebuilding grid. No surpr‚Ä¶                        |\n",
      "|Democrat|RepDarrenSoto|RT @Tharryry: I am delighted that @RepDarrenSoto will be voting for the CRA to overrule the FCC and save our #NetNeutrality rules. Find out‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @HispanicCaucus: Trump's anti-immigrant policies are hurting small businesses across the country that can‚Äôt find Americans willing to do‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @RepStephMurphy: Great joining @WeAreUnidosUS and @RepDarrenSoto for a roundtable in #Orlando on federal issues affecting central Florid‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @AllSaints_FL: Zhihan (John)'s art received awards at this year's state competitions. We just found out he's won the Congressional Distr‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|.@realDonaldTrump official policy to separate immigrant children from their mothers is definition of cruelty‚Ä¶                               |\n",
      "|Democrat|RepDarrenSoto|Thank you to my mom Jean and all the mothers across this nation! You are raising our future. Have a‚Ä¶                                        |\n",
      "|Democrat|RepDarrenSoto|We paid our respects at Nat‚Äôl Law Enforcement Officers Memorial today for those we lost:                                                    |\n",
      "|Other   |NULL         |NULL                                                                                                                                        |\n",
      "|Democrat|RepDarrenSoto|RT @WinterHavenSun: Congratulations to  @AHSbloodhounds senior Abygayle Rausch for starting her service to the country at the US Naval Acad‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|Meet 12 incredible young leaders appointed to US Military Academies from our District! @HispanicCaucus‚Ä¶                                     |\n",
      "|Democrat|RepDarrenSoto|RT @wildlifeaction: With 1/3 of US wildlife in decline, Florida species like the snowy plover need advocates! As co-sponsors for the Recove‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @CHeathWFTV: Keeping guns out of the wrong hands: following @WFTV report, @RepDarrenSoto asks ATF to look into so-called ghost guns (fir‚Ä¶|\n",
      "+--------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "link_pattern = r\"https?://\\S+\"\n",
    "repub_demo_df = repub_demo_df.withColumn(\"Tweet\", regexp_replace(repub_demo_df.Tweet, link_pattern, \"\"))\n",
    "repub_demo_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a72196",
   "metadata": {},
   "source": [
    "## 4. Remove any leading or trailing white space in the tweet column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "166a6d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Party   |Handle       |Tweet                                                                                                                                       |\n",
      "+--------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Democrat|RepDarrenSoto|Today, Senate Dems vote to #SaveTheInternet. Proud to support similar #NetNeutrality legislation here in the House‚Ä¶                         |\n",
      "|Democrat|RepDarrenSoto|RT @WinterHavenSun: Winter Haven resident / Alta Vista teacher is one of several recognized by @RepDarrenSoto for National Teacher Apprecia‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @NBCLatino: .@RepDarrenSoto noted that Hurricane Maria has left approximately $90 billion in damages.                                    |\n",
      "|Other   |NULL         |NULL                                                                                                                                        |\n",
      "|Democrat|RepDarrenSoto|RT @NALCABPolicy: Meeting with @RepDarrenSoto . Thanks for taking the time to meet with @LatinoLeader ED Marucci Guzman. #NALCABPolicy2018.‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @Vegalteno: Hurricane season starts on June 1st; Puerto Rico‚Äôs readiness...well ü§¶üèº‚Äç‚ôÇÔ∏èüò°üò©@Pwr4PuertoRico @RepDarrenSoto @EspaillatNY   |\n",
      "|Democrat|RepDarrenSoto|RT @EmgageActionFL: Thank you to all who came out to our Orlando gala! It was a successful night that would not have been possible without‚Ä¶ |\n",
      "|Democrat|RepDarrenSoto|Hurricane Maria left approx $90 billion in damages, yet only $1 billion was allocated for rebuilding grid. No surpr‚Ä¶                        |\n",
      "|Democrat|RepDarrenSoto|RT @Tharryry: I am delighted that @RepDarrenSoto will be voting for the CRA to overrule the FCC and save our #NetNeutrality rules. Find out‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @HispanicCaucus: Trump's anti-immigrant policies are hurting small businesses across the country that can‚Äôt find Americans willing to do‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @RepStephMurphy: Great joining @WeAreUnidosUS and @RepDarrenSoto for a roundtable in #Orlando on federal issues affecting central Florid‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @AllSaints_FL: Zhihan (John)'s art received awards at this year's state competitions. We just found out he's won the Congressional Distr‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|.@realDonaldTrump official policy to separate immigrant children from their mothers is definition of cruelty‚Ä¶                               |\n",
      "|Democrat|RepDarrenSoto|Thank you to my mom Jean and all the mothers across this nation! You are raising our future. Have a‚Ä¶                                        |\n",
      "|Democrat|RepDarrenSoto|We paid our respects at Nat‚Äôl Law Enforcement Officers Memorial today for those we lost:                                                    |\n",
      "|Other   |NULL         |NULL                                                                                                                                        |\n",
      "|Democrat|RepDarrenSoto|RT @WinterHavenSun: Congratulations to  @AHSbloodhounds senior Abygayle Rausch for starting her service to the country at the US Naval Acad‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|Meet 12 incredible young leaders appointed to US Military Academies from our District! @HispanicCaucus‚Ä¶                                     |\n",
      "|Democrat|RepDarrenSoto|RT @wildlifeaction: With 1/3 of US wildlife in decline, Florida species like the snowy plover need advocates! As co-sponsors for the Recove‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @CHeathWFTV: Keeping guns out of the wrong hands: following @WFTV report, @RepDarrenSoto asks ATF to look into so-called ghost guns (fir‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @GermieNYC: TY, @RepDarrenSoto for calling for the #HFAnow to ensure workers have access to #paidsickdays no matter where they live or w‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|Behind every successful student, there's a proud community of family &amp; teachers. Great to meet with @OCPSnews Avalo‚Ä¶                    |\n",
      "|Democrat|RepDarrenSoto|RT @HeardontheHill: .@RepDarrenSoto recalled playing music at the Dems caucus retreat with @repjoecrowley                                   |\n",
      "|Democrat|RepDarrenSoto|RT @NathanHale7476: Got to meet @RepDarrenSoto today.  #classroomwhereithappens @MrBettsClass @AvalonElem_OCPS @Gilder_Lehrman @SenBillNels‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @WinterHavenSun: Lead story in the Polk News Sun with @RepDarrenSoto and @SenBillNelson . In November voters will decide whether to auto‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|#FACT: 24 percent of Americans said they didn‚Äôt fill a prescription in the previous year because of the high cost.‚Ä¶                         |\n",
      "|Democrat|RepDarrenSoto|Americans deserve #ABetterDeal on the cost of prescription drugs for our seniors ‚Äî one that allows Medicare to nego‚Ä¶                        |\n",
      "|Democrat|RepDarrenSoto|Thank u @BillNye for being a voice for #Science &amp; our Planet! #Sayfie @HispanicCaucus @AudubonFL @SierraClubFL‚Ä¶                         |\n",
      "|Democrat|RepDarrenSoto|RT @RepRubenGallego: Public comment is a responsibility federal agencies have to the public when making critical land management decisions‚Ä¶ |\n",
      "|Democrat|RepDarrenSoto|Sat down with @rollcall to discuss fellowship, getting things done in Congress, my band Orange Creek Riders &amp; hikin‚Ä¶                    |\n",
      "|Democrat|RepDarrenSoto|RT @rvivian370: At the Pulse Memorial this morning representing @RepDarrenSoto. It was a beautiful ceremony honoring the victims and famili‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|Joined colleagues in opposition to Trump admin adding citizenship question to #2020Census. An accurate count is cri‚Ä¶                        |\n",
      "|Democrat|RepDarrenSoto|RT @WFTV: .@RepDarrenSoto calls for regulatory reform of '#ghostguns' after #9Investigates' story  #wftv                                    |\n",
      "|Democrat|RepDarrenSoto|Thank you to millions of bright, hardworking teachers across America who are educating our next generation of leade‚Ä¶                        |\n",
      "|Democrat|RepDarrenSoto|RT @WeAreUnidosUS: Thank you @RepDarrenSoto for joining us today to discuss the devastating effects the proposed cuts to SNAP would have on‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @NAPABA: @RepDarrenSoto ‚Äî the first Puerto Rican congressman from Florida ‚Äî brings the ‚òÄÔ∏è to @NAPABA's 2018 #APAHM Congressional Recepti‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @romancerookie: @RepDarrenSoto @SenBillNelson @marcorubio we need to do something about this. #Insulin4all                               |\n",
      "|Democrat|RepDarrenSoto|RT @WaelAlzayat: Thank you @RepDarrenSoto for being a good friend and an avid supporter of immigrant rights. #EmgagetheHill #EmgageAction h‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @EmgageActionFL: @RepDarrenSoto addressing our team as we prepare to #Emgagethehill @emgageaction                                        |\n",
      "|Democrat|RepDarrenSoto|RT @news6wkmg: .@RepDarrenSoto talks District 9 election with @JustinWarmoth on ‚ÄòThe Weekly‚Äô See the full interview here:                   |\n",
      "|Democrat|RepDarrenSoto|Trump continues anti-immigrant, anti-Hispanic push by ending #TPS for 57,000 #Hondurans - Real solution is pathway‚Ä¶                         |\n",
      "|Democrat|RepDarrenSoto|RT @YourBarrioFL: Thank you @Emerge_USA for hosting @repdarrensoto and myself at your‚Ä¶                                                      |\n",
      "|Democrat|RepDarrenSoto|RT @ricardorossello: Tambi√©n me acompa√±√≥ en la entrega de estos 62 t√≠tulos de propiedad @TATACHARBONIER @Miguel_Romero_ @RepJorgeNavarro @V‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @SenBillNelson: Got a firsthand look at the Ca√±o Mart√≠n Pe√±a Ecosystem Restoration Project in Puerto Rico today. This project is designe‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @garywhite13: Signed by @RepDennisRoss &amp; @RepDarrenSoto but not @TomRooney.                                                          |\n",
      "|Democrat|RepDarrenSoto|It‚Äôs with heavy heart that we mourn loss of Maria Santiago-Burgos, a Puerto Rican survivor of #HurricaneMaria  This‚Ä¶                        |\n",
      "|Democrat|RepDarrenSoto|RT @garywhite13: @SenBillNelson, @RepDarrenSoto discuss restoration of voting rights for felons, census questions during town hall in Haine‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @SenBillNelson: Had a good discussion tonight in Haines City with @RepRichmond and @RepDarrenSoto about Amendment 4 on the November ball‚Ä¶|\n",
      "|Democrat|RepDarrenSoto|RT @YourBarrioFL: At the #vamos4pr press conference and rally with @repdarrensoto celebrating‚Ä¶                                              |\n",
      "|Democrat|RepDarrenSoto|RT @MikeWFerguson: I'm here in Haines City for a civil rights forum, which will touch on voting rights restoration for felons. Those speaki‚Ä¶|\n",
      "+--------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 50 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import trim\n",
    "repub_demo_df = repub_demo_df.withColumn('Tweet', trim(repub_demo_df.Tweet))\n",
    "repub_demo_df.show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd73a0c",
   "metadata": {},
   "source": [
    "## 5. Rename the 'Party' column to 'Dem_Rep'\n",
    "\n",
    "No real reason here :) just wanted you to get practice doing this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0ae7925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------------+\n",
      "| Dem_Rep|       Handle|               Tweet|\n",
      "+--------+-------------+--------------------+\n",
      "|Democrat|RepDarrenSoto|Today, Senate Dem...|\n",
      "|Democrat|RepDarrenSoto|RT @WinterHavenSu...|\n",
      "|Democrat|RepDarrenSoto|RT @NBCLatino: .@...|\n",
      "|   Other|         NULL|                NULL|\n",
      "|Democrat|RepDarrenSoto|RT @NALCABPolicy:...|\n",
      "+--------+-------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "rename_column = repub_demo_df.withColumnRenamed('Party', 'Dem_Rep')\n",
    "rename_column.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72029f3e",
   "metadata": {},
   "source": [
    "## 6. Concatenate the Party and Handle columns\n",
    "\n",
    "Silly yes... but good practice.\n",
    "\n",
    "pyspark.sql.functions.concat_ws(sep, *cols)[source] <br>\n",
    "Concatenates multiple input string columns together into a single string column, using the given separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c3680d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+----------------------+\n",
      "|Party   |Handle       |Party_Handle          |\n",
      "+--------+-------------+----------------------+\n",
      "|Democrat|RepDarrenSoto|Democrat RepDarrenSoto|\n",
      "|Democrat|RepDarrenSoto|Democrat RepDarrenSoto|\n",
      "|Democrat|RepDarrenSoto|Democrat RepDarrenSoto|\n",
      "|Other   |NULL         |Other                 |\n",
      "|Democrat|RepDarrenSoto|Democrat RepDarrenSoto|\n",
      "|Democrat|RepDarrenSoto|Democrat RepDarrenSoto|\n",
      "+--------+-------------+----------------------+\n",
      "only showing top 6 rows\n"
     ]
    }
   ],
   "source": [
    "concatenated_df = repub_demo_df.select(repub_demo_df.Party, repub_demo_df.Handle, concat_ws(' ', repub_demo_df.Party, repub_demo_df.Handle).alias(\"Party_Handle\")).show(6, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b695df79",
   "metadata": {},
   "source": [
    "## Challenge Question\n",
    "\n",
    "Let's image that we want to analyze the hashtags that are used in these tweets. Can you extract all the hashtags you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "455df350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+------------------------+\n",
      "|Party   |Handle       |Tweet                   |\n",
      "+--------+-------------+------------------------+\n",
      "|Democrat|RepDarrenSoto|#SaveTheInternet        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Other   |NULL         |NULL                    |\n",
      "|Democrat|RepDarrenSoto|#NALCABPolicy2018       |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|#NetNeutrality          |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|#Orlando                |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Other   |NULL         |NULL                    |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|#HFAnow                 |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|#classroomwhereithappens|\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|#FACT                   |\n",
      "|Democrat|RepDarrenSoto|#ABetterDeal            |\n",
      "|Democrat|RepDarrenSoto|#Science                |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|#2020Census             |\n",
      "|Democrat|RepDarrenSoto|#ghostguns              |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|#APAHM                  |\n",
      "|Democrat|RepDarrenSoto|#Insulin4all            |\n",
      "|Democrat|RepDarrenSoto|#EmgagetheHill          |\n",
      "|Democrat|RepDarrenSoto|#Emgagethehill          |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|#TPS                    |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|#HurricaneMaria         |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|#vamos4pr               |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|#DemsAtWor              |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Other   |NULL         |NULL                    |\n",
      "|Other   |NULL         |NULL                    |\n",
      "|Other   |NULL         |NULL                    |\n",
      "|Other   |NULL         |NULL                    |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "|Democrat|RepDarrenSoto|                        |\n",
      "+--------+-------------+------------------------+\n",
      "only showing top 60 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "pattern = r\"#\\w+\"\n",
    "df_hastags = repub_demo_df.withColumn(\"Tweet\", regexp_extract(\"Tweet\", pattern, 0))\n",
    "df_hastags.show(60, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f07e6ed",
   "metadata": {},
   "source": [
    "# Let's create our own dataset to work with real dates\n",
    "\n",
    "This is a dataset of patient visits from a medical office. It contains the patients first and last names, date of birth, and the dates of their first 3 visits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8145d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+--------+---------+---------+\n",
      "|first_name|last_name|       dob|  visit1|   visit2|   visit3|\n",
      "+----------+---------+----------+--------+---------+---------+\n",
      "|  Mohammed|   Alfasy|  1987-4-8|2016-1-7| 2017-2-3| 2018-3-2|\n",
      "|     Marcy|Wellmaker|  1986-4-8|2015-1-7| 2017-1-3| 2018-1-2|\n",
      "|     Ginny|   Ginger| 1986-7-10|2014-8-7| 2015-2-3| 2016-3-2|\n",
      "|     Vijay| Doberson|  1988-5-2|2016-1-7| 2018-2-3| 2018-3-2|\n",
      "|     Orhan|  Gelicek| 1987-5-11|2016-5-7| 2017-1-3| 2018-9-2|\n",
      "|     Sarah|    Jones|  1956-7-6|2016-4-7| 2017-8-3|2018-10-2|\n",
      "|      John|  Johnson|2017-10-12|2018-1-2|2018-10-3| 2018-3-2|\n",
      "+----------+---------+----------+--------+---------+---------+\n",
      "\n",
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- visit1: string (nullable = true)\n",
      " |-- visit2: string (nullable = true)\n",
      " |-- visit3: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "md_office = [('Mohammed','Alfasy','1987-4-8','2016-1-7','2017-2-3','2018-3-2') \\\n",
    "            ,('Marcy','Wellmaker','1986-4-8','2015-1-7','2017-1-3','2018-1-2') \\\n",
    "            ,('Ginny','Ginger','1986-7-10','2014-8-7','2015-2-3','2016-3-2') \\\n",
    "            ,('Vijay','Doberson','1988-5-2','2016-1-7','2018-2-3','2018-3-2') \\\n",
    "            ,('Orhan','Gelicek','1987-5-11','2016-5-7','2017-1-3','2018-9-2') \\\n",
    "            ,('Sarah','Jones','1956-7-6','2016-4-7','2017-8-3','2018-10-2') \\\n",
    "            ,('John','Johnson','2017-10-12','2018-1-2','2018-10-3','2018-3-2') ]\n",
    "\n",
    "df = spark.createDataFrame(md_office,['first_name','last_name','dob','visit1','visit2','visit3']) # schema=final_struc\n",
    "\n",
    "# Check to make sure it worked\n",
    "df.show()\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad254365",
   "metadata": {},
   "source": [
    "Oh no! The dates are still stored as text... let's try converting them again and see if we have any issues this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "36156123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- dob: date (nullable = true)\n",
      " |-- visit1: date (nullable = true)\n",
      " |-- visit2: date (nullable = true)\n",
      " |-- visit3: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = df.withColumn(\"dob\", df[\"dob\"].cast(DateType()))\\\n",
    ".withColumn(\"visit1\", df['visit1'].cast(DateType()))\\\n",
    ".withColumn(\"visit2\", df['visit2'].cast(DateType()))\\\n",
    ".withColumn(\"visit3\", df['visit3'].cast(DateType()))\n",
    "\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd11b2",
   "metadata": {},
   "source": [
    "## 7. Can you calculate a variable showing the length of time between patient visits?\n",
    "\n",
    "Compare visit1 to visit2 and visit2 to visit3 for all patients and see what the average length of time is between visits. Create an alias for it as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "58282aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|visit_2_1|\n",
      "+---------+\n",
      "|      393|\n",
      "|      727|\n",
      "|      180|\n",
      "|      758|\n",
      "|      241|\n",
      "|      483|\n",
      "|      274|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visit_2_1 = df.select(datediff(df.visit2, df.visit1).alias('visit_2_1')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8ef021cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|visit_3_2|\n",
      "+---------+\n",
      "|      392|\n",
      "|      364|\n",
      "|      393|\n",
      "|       27|\n",
      "|      607|\n",
      "|      425|\n",
      "|     -215|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visit_3_2 = df.select(datediff(df.visit3, df.visit2).alias('visit_3_2')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a054588",
   "metadata": {},
   "source": [
    "## 8. Can you calculate the age of each patient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3e75a6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+--------+---------+---------+---+\n",
      "|first_name|last_name|       dob|  visit1|   visit2|   visit3|age|\n",
      "+----------+---------+----------+--------+---------+---------+---+\n",
      "|  Mohammed|   Alfasy|  1987-4-8|2016-1-7| 2017-2-3| 2018-3-2| 38|\n",
      "|     Marcy|Wellmaker|  1986-4-8|2015-1-7| 2017-1-3| 2018-1-2| 39|\n",
      "|     Ginny|   Ginger| 1986-7-10|2014-8-7| 2015-2-3| 2016-3-2| 39|\n",
      "|     Vijay| Doberson|  1988-5-2|2016-1-7| 2018-2-3| 2018-3-2| 37|\n",
      "|     Orhan|  Gelicek| 1987-5-11|2016-5-7| 2017-1-3| 2018-9-2| 38|\n",
      "|     Sarah|    Jones|  1956-7-6|2016-4-7| 2017-8-3|2018-10-2| 69|\n",
      "|      John|  Johnson|2017-10-12|2018-1-2|2018-10-3| 2018-3-2|  8|\n",
      "+----------+---------+----------+--------+---------+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "age = fn.year(fn.current_date()) - fn.year('dob')\n",
    "df.withColumn(\"age\", age).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e2953b",
   "metadata": {},
   "source": [
    "## 9. Can you extract the month from the first visit column and call it \"Month\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2b8c10fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+--------+---------+---------+-----+\n",
      "|first_name|last_name|       dob|  visit1|   visit2|   visit3|month|\n",
      "+----------+---------+----------+--------+---------+---------+-----+\n",
      "|  Mohammed|   Alfasy|  1987-4-8|2016-1-7| 2017-2-3| 2018-3-2|    1|\n",
      "|     Marcy|Wellmaker|  1986-4-8|2015-1-7| 2017-1-3| 2018-1-2|    1|\n",
      "|     Ginny|   Ginger| 1986-7-10|2014-8-7| 2015-2-3| 2016-3-2|    8|\n",
      "|     Vijay| Doberson|  1988-5-2|2016-1-7| 2018-2-3| 2018-3-2|    1|\n",
      "|     Orhan|  Gelicek| 1987-5-11|2016-5-7| 2017-1-3| 2018-9-2|    5|\n",
      "|     Sarah|    Jones|  1956-7-6|2016-4-7| 2017-8-3|2018-10-2|    4|\n",
      "|      John|  Johnson|2017-10-12|2018-1-2|2018-10-3| 2018-3-2|    1|\n",
      "+----------+---------+----------+--------+---------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "month = df.withColumn(\"month\", fn.month('visit1')).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7d954f",
   "metadata": {},
   "source": [
    "## 10. Challenges with working with date and timestamps\n",
    "\n",
    "Let's read in the supermarket sales dataframe attached to the lecture now and see some of the issues that can come up when working with date and timestamps values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "39af4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "supermarket_sales = spark.read.csv('Datasets/supermarket_sales.csv', inferSchema=True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47ab97f",
   "metadata": {},
   "source": [
    "## About this dataset\n",
    "\n",
    "The growth of supermarkets in most populated cities are increasing and market competitions are also high. The dataset is one of the historical sales of supermarket company which has recorded in 3 different branches for 3 months data. \n",
    "\n",
    " - Attribute information\n",
    " - Invoice id: Computer generated sales slip invoice identification number\n",
    " - Branch: Branch of supercenter (3 branches are available identified by A, B and C).\n",
    " - City: Location of supercenters\n",
    " - Customer type: Type of customers, recorded by Members for customers using member card and Normal for without member card.\n",
    " - Gender: Gender type of customer\n",
    " - Product line: General item categorization groups - Electronic accessories, Fashion accessories, Food and beverages, Health and beauty, Home and lifestyle, Sports and travel\n",
    " - Unit price: Price of each product in USD\n",
    " - Quantity: Number of products purchased by customer\n",
    " - Tax: 5% tax fee for customer buying\n",
    " - Total: Total price including tax\n",
    " - Date: Date of purchase (Record available from January 2019 to March 2019)\n",
    " - Time: Purchase time (10am to 9pm)\n",
    " - Payment: Payment used by customer for purchase (3 methods are available ‚Äì Cash, Credit card and Ewallet)\n",
    " - COGS: Cost of goods sold\n",
    " - Gross margin percentage: Gross margin percentage\n",
    " - Gross income: Gross income\n",
    " - Rating: Customer stratification rating on their overall shopping experience (On a scale of 1 to 10)\n",
    "\n",
    "**Source:** https://www.kaggle.com/aungpyaeap/supermarket-sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b544952",
   "metadata": {},
   "source": [
    "### View dataframe and schema as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0439347a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+---------+-------------+------+--------------------+----------+--------+-------+--------+---------+-------------------+-----------+------+-----------------------+------------+------+\n",
      "| Invoice ID|Branch|     City|Customer type|Gender|        Product line|Unit price|Quantity| Tax 5%|   Total|     Date|               Time|    Payment|  cogs|gross margin percentage|gross income|Rating|\n",
      "+-----------+------+---------+-------------+------+--------------------+----------+--------+-------+--------+---------+-------------------+-----------+------+-----------------------+------------+------+\n",
      "|750-67-8428|     A|   Yangon|       Member|Female|   Health and beauty|     74.69|       7|26.1415|548.9715| 1/5/2019|2025-11-15 13:08:00|    Ewallet|522.83|            4.761904762|     26.1415|   9.1|\n",
      "|226-31-3081|     C|Naypyitaw|       Normal|Female|Electronic access...|     15.28|       5|   3.82|   80.22| 3/8/2019|2025-11-15 10:29:00|       Cash|  76.4|            4.761904762|        3.82|   9.6|\n",
      "|631-41-3108|     A|   Yangon|       Normal|  Male|  Home and lifestyle|     46.33|       7|16.2155|340.5255| 3/3/2019|2025-11-15 13:23:00|Credit card|324.31|            4.761904762|     16.2155|   7.4|\n",
      "|123-19-1176|     A|   Yangon|       Member|  Male|   Health and beauty|     58.22|       8| 23.288| 489.048|1/27/2019|2025-11-15 20:33:00|    Ewallet|465.76|            4.761904762|      23.288|   8.4|\n",
      "|373-73-7910|     A|   Yangon|       Normal|  Male|   Sports and travel|     86.31|       7|30.2085|634.3785| 2/8/2019|2025-11-15 10:37:00|    Ewallet|604.17|            4.761904762|     30.2085|   5.3|\n",
      "|699-14-3026|     C|Naypyitaw|       Normal|  Male|Electronic access...|     85.39|       7|29.8865|627.6165|3/25/2019|2025-11-15 18:30:00|    Ewallet|597.73|            4.761904762|     29.8865|   4.1|\n",
      "|355-53-5943|     A|   Yangon|       Member|Female|Electronic access...|     68.84|       6| 20.652| 433.692|2/25/2019|2025-11-15 14:36:00|    Ewallet|413.04|            4.761904762|      20.652|   5.8|\n",
      "|315-22-5665|     C|Naypyitaw|       Normal|Female|  Home and lifestyle|     73.56|      10|  36.78|  772.38|2/24/2019|2025-11-15 11:38:00|    Ewallet| 735.6|            4.761904762|       36.78|   8.0|\n",
      "|665-32-9167|     A|   Yangon|       Member|Female|   Health and beauty|     36.26|       2|  3.626|  76.146|1/10/2019|2025-11-15 17:15:00|Credit card| 72.52|            4.761904762|       3.626|   7.2|\n",
      "|692-92-5582|     B| Mandalay|       Member|Female|  Food and beverages|     54.84|       3|  8.226| 172.746|2/20/2019|2025-11-15 13:27:00|Credit card|164.52|            4.761904762|       8.226|   5.9|\n",
      "|351-62-0822|     B| Mandalay|       Member|Female| Fashion accessories|     14.48|       4|  2.896|  60.816| 2/6/2019|2025-11-15 18:07:00|    Ewallet| 57.92|            4.761904762|       2.896|   4.5|\n",
      "|529-56-3974|     B| Mandalay|       Member|  Male|Electronic access...|     25.51|       4|  5.102| 107.142| 3/9/2019|2025-11-15 17:03:00|       Cash|102.04|            4.761904762|       5.102|   6.8|\n",
      "|365-64-0515|     A|   Yangon|       Normal|Female|Electronic access...|     46.95|       5|11.7375|246.4875|2/12/2019|2025-11-15 10:25:00|    Ewallet|234.75|            4.761904762|     11.7375|   7.1|\n",
      "|252-56-2699|     A|   Yangon|       Normal|  Male|  Food and beverages|     43.19|      10| 21.595| 453.495| 2/7/2019|2025-11-15 16:48:00|    Ewallet| 431.9|            4.761904762|      21.595|   8.2|\n",
      "|829-34-3910|     A|   Yangon|       Normal|Female|   Health and beauty|     71.38|      10|  35.69|  749.49|3/29/2019|2025-11-15 19:21:00|       Cash| 713.8|            4.761904762|       35.69|   5.7|\n",
      "|299-46-1805|     B| Mandalay|       Member|Female|   Sports and travel|     93.72|       6| 28.116| 590.436|1/15/2019|2025-11-15 16:19:00|       Cash|562.32|            4.761904762|      28.116|   4.5|\n",
      "|656-95-9349|     A|   Yangon|       Member|Female|   Health and beauty|     68.93|       7|24.1255|506.6355|3/11/2019|2025-11-15 11:03:00|Credit card|482.51|            4.761904762|     24.1255|   4.6|\n",
      "|765-26-6951|     A|   Yangon|       Normal|  Male|   Sports and travel|     72.61|       6| 21.783| 457.443| 1/1/2019|2025-11-15 10:39:00|Credit card|435.66|            4.761904762|      21.783|   6.9|\n",
      "|329-62-1586|     A|   Yangon|       Normal|  Male|  Food and beverages|     54.67|       3| 8.2005|172.2105|1/21/2019|2025-11-15 18:00:00|Credit card|164.01|            4.761904762|      8.2005|   8.6|\n",
      "|319-50-3348|     B| Mandalay|       Normal|Female|  Home and lifestyle|      40.3|       2|   4.03|   84.63|3/11/2019|2025-11-15 15:30:00|    Ewallet|  80.6|            4.761904762|        4.03|   4.4|\n",
      "+-----------+------+---------+-------------+------+--------------------+----------+--------+-------+--------+---------+-------------------+-----------+------+-----------------------+------------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "supermarket_sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3975a7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Invoice ID: string (nullable = true)\n",
      " |-- Branch: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Customer type: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Product line: string (nullable = true)\n",
      " |-- Unit price: double (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- Tax 5%: double (nullable = true)\n",
      " |-- Total: double (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Time: timestamp (nullable = true)\n",
      " |-- Payment: string (nullable = true)\n",
      " |-- cogs: double (nullable = true)\n",
      " |-- gross margin percentage: double (nullable = true)\n",
      " |-- gross income: double (nullable = true)\n",
      " |-- Rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "supermarket_sales.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5189a85b",
   "metadata": {},
   "source": [
    "### Convert date field to date type\n",
    "\n",
    "Looks like we need to convert the date field into a date type. Let's go ahead and do that.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7b0cad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "supermarket_sales = supermarket_sales.withColumn(\n",
    "    \"Date\",\n",
    "    to_date(\"Date\", \"M/d/yyyy\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ce0da026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateType()"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supermarket_sales.schema['Date'].dataType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df3496f",
   "metadata": {},
   "source": [
    "### How can we extract the month value from the date field?\n",
    "\n",
    "If you had trouble converting the date field in the previous question think about a more creative solution to extract the month from that field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a8f9ecb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      Date|month|\n",
      "+----------+-----+\n",
      "|2019-01-05|    1|\n",
      "|2019-03-08|    3|\n",
      "|2019-03-03|    3|\n",
      "|2019-01-27|    1|\n",
      "|2019-02-08|    2|\n",
      "|2019-03-25|    3|\n",
      "|2019-02-25|    2|\n",
      "|2019-02-24|    2|\n",
      "|2019-01-10|    1|\n",
      "|2019-02-20|    2|\n",
      "|2019-02-06|    2|\n",
      "|2019-03-09|    3|\n",
      "|2019-02-12|    2|\n",
      "|2019-02-07|    2|\n",
      "|2019-03-29|    3|\n",
      "|2019-01-15|    1|\n",
      "|2019-03-11|    3|\n",
      "|2019-01-01|    1|\n",
      "|2019-01-21|    1|\n",
      "|2019-03-11|    3|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import month, col\n",
    "supermarket_sales = supermarket_sales.withColumn(\"month\", month(col('Date')))\n",
    "supermarket_sales.select(\"Date\", \"month\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1448660d",
   "metadata": {},
   "source": [
    "## 11.0 Working with Arrays\n",
    "\n",
    "Here is a dataframe of reviews from the movie the Dark Night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "84081250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------------------------------------------------------------------+\n",
      "|rating|review_txt                                                                            |\n",
      "+------+--------------------------------------------------------------------------------------+\n",
      "|5     |Epic. This is the best movie I have EVER seen                                         |\n",
      "|4     |Pretty good, but I would have liked to seen better special effects                    |\n",
      "|3     |So so. Casting could have been improved                                               |\n",
      "|5     |The most EPIC movie of the year! Casting was awesome. Special effects were so intense.|\n",
      "|4     |Solid but I would have liked to see more of the love story                            |\n",
      "|5     |THE BOMB!!!!!!!                                                                       |\n",
      "+------+--------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "values = [(5,'Epic. This is the best movie I have EVER seen'), \\\n",
    "          (4,'Pretty good, but I would have liked to seen better special effects'), \\\n",
    "          (3,'So so. Casting could have been improved'), \\\n",
    "          (5,'The most EPIC movie of the year! Casting was awesome. Special effects were so intense.'), \\\n",
    "          (4,'Solid but I would have liked to see more of the love story'), \\\n",
    "          (5,'THE BOMB!!!!!!!')]\n",
    "reviews = spark.createDataFrame(values,['rating', 'review_txt'])\n",
    "\n",
    "reviews.show(6,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4dbae5",
   "metadata": {},
   "source": [
    "## 11.1 Let's see if we can create an array off of the review text column and then derive some meaningful results from it.\n",
    "\n",
    "**But first** we need to clean the rview_txt column to make sure we can get what we need from our analysis later on. So let's do the following:\n",
    "\n",
    "1. Remove all punctuation\n",
    "2. lower case everything\n",
    "3. Remove white space (trim)\n",
    "3. Then finally, split the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4d60c98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------------------------------------------------------------+\n",
      "|rating|review_txt                                                                         |\n",
      "+------+-----------------------------------------------------------------------------------+\n",
      "|5     |Epic This is the best movie I have EVER seen                                       |\n",
      "|4     |Pretty good but I would have liked to seen better special effects                  |\n",
      "|3     |So so Casting could have been improved                                             |\n",
      "|5     |The most EPIC movie of the year Casting was awesome Special effects were so intense|\n",
      "|4     |Solid but I would have liked to see more of the love story                         |\n",
      "|5     |THE BOMB                                                                           |\n",
      "+------+-----------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove all punctuation\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "reviews_cleaned = reviews.withColumn(\"review_txt\", regexp_replace(reviews.review_txt, \"[^a-zA-Z\\\\s]\", \"\"))\n",
    "reviews_cleaned.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1826adda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------------------------------------------------------------+\n",
      "|rating|review_txt                                                                         |\n",
      "+------+-----------------------------------------------------------------------------------+\n",
      "|5     |epic this is the best movie i have ever seen                                       |\n",
      "|4     |pretty good but i would have liked to seen better special effects                  |\n",
      "|3     |so so casting could have been improved                                             |\n",
      "|5     |the most epic movie of the year casting was awesome special effects were so intense|\n",
      "|4     |solid but i would have liked to see more of the love story                         |\n",
      "|5     |the bomb                                                                           |\n",
      "+------+-----------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lower case everything\n",
    "reviews_cleaned = reviews_cleaned.withColumn(\"review_txt\", lower(reviews_cleaned.review_txt))\n",
    "reviews_cleaned.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5bc7ba57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------------------------------------------------------------+\n",
      "|rating|review_txt                                                                         |\n",
      "+------+-----------------------------------------------------------------------------------+\n",
      "|5     |epic this is the best movie i have ever seen                                       |\n",
      "|4     |pretty good but i would have liked to seen better special effects                  |\n",
      "|3     |so so casting could have been improved                                             |\n",
      "|5     |the most epic movie of the year casting was awesome special effects were so intense|\n",
      "|4     |solid but i would have liked to see more of the love story                         |\n",
      "|5     |the bomb                                                                           |\n",
      "+------+-----------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove white space (trim)\n",
    "reviews_cleaned =reviews_cleaned.withColumn('review_txt', trim(reviews_cleaned.review_txt))\n",
    "reviews_cleaned.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e8b69570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|rating|          review_txt|               array|\n",
      "+------+--------------------+--------------------+\n",
      "|     5|epic this is the ...|[epic, this, is, ...|\n",
      "|     4|pretty good but i...|[pretty, good, bu...|\n",
      "|     3|so so casting cou...|[so, so, casting,...|\n",
      "|     5|the most epic mov...|[the, most, epic,...|\n",
      "|     4|solid but i would...|[solid, but, i, w...|\n",
      "|     5|            the bomb|         [the, bomb]|\n",
      "+------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the string\n",
    "reviews_cleaned = reviews_cleaned.withColumn(\"array\", split(reviews_cleaned.review_txt, \" \"))\n",
    "reviews_cleaned.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ab3608",
   "metadata": {},
   "source": [
    "## 11.2 Alright now let's see if we can find which reviews contain the word 'Epic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fac1cdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------------------------------------------------------------------+\n",
      "|rating|review_txt                                                                            |\n",
      "+------+--------------------------------------------------------------------------------------+\n",
      "|5     |Epic. This is the best movie I have EVER seen                                         |\n",
      "|5     |The most EPIC movie of the year! Casting was awesome. Special effects were so intense.|\n",
      "+------+--------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.filter(lower(reviews.review_txt).contains(\"epic\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7760b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c86afc",
   "metadata": {},
   "source": [
    "# **Part 3: Joining and Appending DataFrames in PySpark HW**\n",
    "\n",
    "Now it's time to test your knowledge and further engrain the concepts we touched on in the lectures. Let's go ahead and get started.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**As always let's start our Spark instance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "375f341f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/15 20:47:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.6.254.236:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Part3</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x121de7b60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Part3\").getOrCreate()\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a41264",
   "metadata": {},
   "source": [
    "## Read in the database\n",
    "\n",
    "Let cotinue working with our college courses dataframe to get some more insights and practice what we have learned!Let's read in the whole database using the loop function that we learned about in the lecture to automatically read in all the datasets from the uw-madision-courses folder (there are too many datasets to each one individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127a8799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/15 20:48:05 WARN DAGScheduler: Broadcasting large task binary with size 8.2 MiB\n",
      "25/11/15 20:48:08 WARN DAGScheduler: Broadcasting large task binary with size 28.1 MiB\n",
      "[Stage 19:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full list of data frames found:\n",
      "['subjects', 'subject_memberships', 'rooms', 'schedules', 'sections', 'courses', 'course_offerings', 'instructors', 'teachings', 'grade_distributions']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"madison_courses/\"\n",
    "\n",
    "df_list = []\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filename_list = filename.split(\".\") \n",
    "        df_name = filename_list[0]\n",
    "        df = spark.read.csv(path+filename,inferSchema=True,header=True)\n",
    "        df.name = df_name\n",
    "        df_list.append(df_name)\n",
    "        exec(df_name + ' = df')\n",
    "        \n",
    "print(\"Full list of data frames found:\")\n",
    "print(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe2337",
   "metadata": {},
   "source": [
    "Now check the contents of a few of the dataframses that were read in above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aafb1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- course_offering_uuid: string (nullable = true)\n",
      " |-- section_number: integer (nullable = true)\n",
      " |-- a_count: integer (nullable = true)\n",
      " |-- ab_count: integer (nullable = true)\n",
      " |-- b_count: integer (nullable = true)\n",
      " |-- bc_count: integer (nullable = true)\n",
      " |-- c_count: integer (nullable = true)\n",
      " |-- d_count: integer (nullable = true)\n",
      " |-- f_count: integer (nullable = true)\n",
      " |-- s_count: integer (nullable = true)\n",
      " |-- u_count: integer (nullable = true)\n",
      " |-- cr_count: integer (nullable = true)\n",
      " |-- n_count: integer (nullable = true)\n",
      " |-- p_count: integer (nullable = true)\n",
      " |-- i_count: integer (nullable = true)\n",
      " |-- nw_count: integer (nullable = true)\n",
      " |-- nr_count: integer (nullable = true)\n",
      " |-- other_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grade_distributions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35a133f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_offering_uuid</th>\n",
       "      <th>section_number</th>\n",
       "      <th>a_count</th>\n",
       "      <th>ab_count</th>\n",
       "      <th>b_count</th>\n",
       "      <th>bc_count</th>\n",
       "      <th>c_count</th>\n",
       "      <th>d_count</th>\n",
       "      <th>f_count</th>\n",
       "      <th>s_count</th>\n",
       "      <th>u_count</th>\n",
       "      <th>cr_count</th>\n",
       "      <th>n_count</th>\n",
       "      <th>p_count</th>\n",
       "      <th>i_count</th>\n",
       "      <th>nw_count</th>\n",
       "      <th>nr_count</th>\n",
       "      <th>other_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344b3ebe-da7e-314c-83ed-9425269695fd</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f718e6cd-33f0-3c14-a9a6-834d9c3610a8</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ea3b717c-d66b-30dc-8b37-964d9688295f</td>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>075da420-5f49-3dd0-93df-13e3c152e1b1</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2b4e216d-a728-3713-8c7c-19afffc6b2fd</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>87966a7b-f676-33d0-83d2-acdb67da6790</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ff511882-5eab-3e7b-a89f-8fbfd1906127</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b3e26604-fe6e-30df-bc91-b5fa57717a7e</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e100d196-5e82-32e4-80e9-ac45c07a498c</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>76b9c458-d3c2-38c4-951f-69b6900bd7fe</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2cd95315-cc90-33d6-9670-6d4eaddb7104</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b729bdbf-c272-3d36-ba1b-b428217b037b</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>c94b0026-46e5-3183-9e02-f0d8616b020e</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>e6fe4acb-9375-3b46-9d16-6d6ae716d80a</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>73eb2c88-a7c0-36db-872f-b2fc0c1c956d</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    course_offering_uuid  section_number  a_count  ab_count  \\\n",
       "0   344b3ebe-da7e-314c-83ed-9425269695fd               1      105         0   \n",
       "1   f718e6cd-33f0-3c14-a9a6-834d9c3610a8               1      158         0   \n",
       "2   ea3b717c-d66b-30dc-8b37-964d9688295f               1      139        12   \n",
       "3   075da420-5f49-3dd0-93df-13e3c152e1b1               1       87         0   \n",
       "4   2b4e216d-a728-3713-8c7c-19afffc6b2fd               1       70         0   \n",
       "5   87966a7b-f676-33d0-83d2-acdb67da6790               1       79         0   \n",
       "6   ff511882-5eab-3e7b-a89f-8fbfd1906127               1      114         3   \n",
       "7   b3e26604-fe6e-30df-bc91-b5fa57717a7e               1      105         1   \n",
       "8   e100d196-5e82-32e4-80e9-ac45c07a498c               1      107         3   \n",
       "9   76b9c458-d3c2-38c4-951f-69b6900bd7fe               1      129         8   \n",
       "10  2cd95315-cc90-33d6-9670-6d4eaddb7104               1      135         0   \n",
       "11  b729bdbf-c272-3d36-ba1b-b428217b037b               1      111         0   \n",
       "12  c94b0026-46e5-3183-9e02-f0d8616b020e               1      114         3   \n",
       "13  e6fe4acb-9375-3b46-9d16-6d6ae716d80a               1      118         6   \n",
       "14  73eb2c88-a7c0-36db-872f-b2fc0c1c956d               1      137         0   \n",
       "\n",
       "    b_count  bc_count  c_count  d_count  f_count  s_count  u_count  cr_count  \\\n",
       "0         0         0        0        0        0        0        0         0   \n",
       "1         0         0        0        0        0        0        0         0   \n",
       "2         2         0        3        0        0        0        0         0   \n",
       "3         0         0        0        0        0        0        0         0   \n",
       "4         0         0        0        0        0        0        0         0   \n",
       "5         0         0        0        0        0        0        0         0   \n",
       "6         1         0        0        0        0        0        0         0   \n",
       "7         0         0        0        0        1        0        0         0   \n",
       "8         1         0        0        0        0        0        0         0   \n",
       "9         2         0        1        1        0        0        0         0   \n",
       "10        0         0        0        0        0        0        0         0   \n",
       "11        0         0        0        0        0        0        0         0   \n",
       "12        1         0        2        2        0        0        0         0   \n",
       "13        2         0        1        1        1        0        0         0   \n",
       "14        4         0        0        0        0        0        0         0   \n",
       "\n",
       "    n_count  p_count  i_count  nw_count  nr_count  other_count  \n",
       "0         0        0        0         0         0            0  \n",
       "1         0        0        1         0         0            0  \n",
       "2         0        0        0         0         0            0  \n",
       "3         0        0        1         0         0            0  \n",
       "4         0        0        1         0         0            0  \n",
       "5         0        0       12         0         0            0  \n",
       "6         0        0        3         0         0            0  \n",
       "7         0        0        0         0         0            0  \n",
       "8         0        0        2         0         0            0  \n",
       "9         0        0        3         0         0            0  \n",
       "10        0        0        7         0         0            0  \n",
       "11        0        0        3         0         0            0  \n",
       "12        0        0        1         0         0            0  \n",
       "13        0        0       15         0         0            0  \n",
       "14        0        0       11         0         0            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_distributions.limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb65904f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uuid: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- number: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "courses.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7f6671d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>name</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>Cooperative Education Program</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c070a84f-648f-351d-9499-5d0e30ad02cc</td>\n",
       "      <td>Cooperative Education/Co-op in Life Sciences C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e6b4b7ae-0e0b-3aa5-9d77-7fcd90c9cfa3</td>\n",
       "      <td>Cooperative Education Program</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8f63bde1-ff7f-3fe7-9901-862908bf134c</td>\n",
       "      <td>Workshop in Dance Activity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f3541888-584a-3923-9ce7-6341ff3d84a1</td>\n",
       "      <td>Cooperative Education/Co-op in Agricultural &amp; ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d07193c1-551e-3c4d-82cd-7059fc2cd512</td>\n",
       "      <td>Ballroom Dance I</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eb1a8a08-a675-3c45-aa49-23a6589fed56</td>\n",
       "      <td>Fundamentals-Flute</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>57540351-0e4a-3528-9ac0-84e8f72b41bc</td>\n",
       "      <td>Contemporary Dance I</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0422e04f-96d2-3b9f-ba5e-4ed3a43173f6</td>\n",
       "      <td>Fundamentals: Single Reeds</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3e2fe18a-32f9-3e6f-a627-f77481eb84d9</td>\n",
       "      <td>Fundamentals-Low Brass</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>e26a2ec7-13ee-346b-a89f-c71e34c0a1e1</td>\n",
       "      <td>Fundamentals-Percussion</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>34188bed-84e7-318b-9d5f-34b4c33e7d0e</td>\n",
       "      <td>Fundamentals-High Strings</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a4f57833-e0d4-3e68-ab57-15370781370e</td>\n",
       "      <td>Fundamentals-Low Strings</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ff31520a-b86c-308e-a9d1-302ec27c91ee</td>\n",
       "      <td>Wind Ensemble</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6b28c9cc-9542-37c4-aa81-32c213581086</td>\n",
       "      <td>Concert Band</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uuid  \\\n",
       "0   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de   \n",
       "1   c070a84f-648f-351d-9499-5d0e30ad02cc   \n",
       "2   e6b4b7ae-0e0b-3aa5-9d77-7fcd90c9cfa3   \n",
       "3   8f63bde1-ff7f-3fe7-9901-862908bf134c   \n",
       "4   f3541888-584a-3923-9ce7-6341ff3d84a1   \n",
       "5   d07193c1-551e-3c4d-82cd-7059fc2cd512   \n",
       "6   eb1a8a08-a675-3c45-aa49-23a6589fed56   \n",
       "7   57540351-0e4a-3528-9ac0-84e8f72b41bc   \n",
       "8   0422e04f-96d2-3b9f-ba5e-4ed3a43173f6   \n",
       "9   3e2fe18a-32f9-3e6f-a627-f77481eb84d9   \n",
       "10  e26a2ec7-13ee-346b-a89f-c71e34c0a1e1   \n",
       "11  34188bed-84e7-318b-9d5f-34b4c33e7d0e   \n",
       "12  a4f57833-e0d4-3e68-ab57-15370781370e   \n",
       "13  ff31520a-b86c-308e-a9d1-302ec27c91ee   \n",
       "14  6b28c9cc-9542-37c4-aa81-32c213581086   \n",
       "\n",
       "                                                 name  number  \n",
       "0                       Cooperative Education Program       1  \n",
       "1   Cooperative Education/Co-op in Life Sciences C...       1  \n",
       "2                       Cooperative Education Program       1  \n",
       "3                          Workshop in Dance Activity       1  \n",
       "4   Cooperative Education/Co-op in Agricultural & ...       1  \n",
       "5                                    Ballroom Dance I       2  \n",
       "6                                  Fundamentals-Flute       7  \n",
       "7                                Contemporary Dance I      11  \n",
       "8                          Fundamentals: Single Reeds      14  \n",
       "9                              Fundamentals-Low Brass      24  \n",
       "10                            Fundamentals-Percussion      27  \n",
       "11                          Fundamentals-High Strings      32  \n",
       "12                           Fundamentals-Low Strings      36  \n",
       "13                                      Wind Ensemble      40  \n",
       "14                                       Concert Band      41  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "courses.limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16479f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>course_uuid</th>\n",
       "      <th>term_code</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344b3ebe-da7e-314c-83ed-9425269695fd</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1092</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f718e6cd-33f0-3c14-a9a6-834d9c3610a8</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1082</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ea3b717c-d66b-30dc-8b37-964d9688295f</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1172</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>075da420-5f49-3dd0-93df-13e3c152e1b1</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1114</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2b4e216d-a728-3713-8c7c-19afffc6b2fd</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1104</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>87966a7b-f676-33d0-83d2-acdb67da6790</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1112</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ff511882-5eab-3e7b-a89f-8fbfd1906127</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1134</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b3e26604-fe6e-30df-bc91-b5fa57717a7e</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1084</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e100d196-5e82-32e4-80e9-ac45c07a498c</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1154</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>76b9c458-d3c2-38c4-951f-69b6900bd7fe</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1162</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2cd95315-cc90-33d6-9670-6d4eaddb7104</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1132</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b729bdbf-c272-3d36-ba1b-b428217b037b</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1122</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>c94b0026-46e5-3183-9e02-f0d8616b020e</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1142</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>e6fe4acb-9375-3b46-9d16-6d6ae716d80a</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1152</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>73eb2c88-a7c0-36db-872f-b2fc0c1c956d</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1144</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uuid  \\\n",
       "0   344b3ebe-da7e-314c-83ed-9425269695fd   \n",
       "1   f718e6cd-33f0-3c14-a9a6-834d9c3610a8   \n",
       "2   ea3b717c-d66b-30dc-8b37-964d9688295f   \n",
       "3   075da420-5f49-3dd0-93df-13e3c152e1b1   \n",
       "4   2b4e216d-a728-3713-8c7c-19afffc6b2fd   \n",
       "5   87966a7b-f676-33d0-83d2-acdb67da6790   \n",
       "6   ff511882-5eab-3e7b-a89f-8fbfd1906127   \n",
       "7   b3e26604-fe6e-30df-bc91-b5fa57717a7e   \n",
       "8   e100d196-5e82-32e4-80e9-ac45c07a498c   \n",
       "9   76b9c458-d3c2-38c4-951f-69b6900bd7fe   \n",
       "10  2cd95315-cc90-33d6-9670-6d4eaddb7104   \n",
       "11  b729bdbf-c272-3d36-ba1b-b428217b037b   \n",
       "12  c94b0026-46e5-3183-9e02-f0d8616b020e   \n",
       "13  e6fe4acb-9375-3b46-9d16-6d6ae716d80a   \n",
       "14  73eb2c88-a7c0-36db-872f-b2fc0c1c956d   \n",
       "\n",
       "                             course_uuid  term_code  \\\n",
       "0   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1092   \n",
       "1   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1082   \n",
       "2   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1172   \n",
       "3   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1114   \n",
       "4   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1104   \n",
       "5   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1112   \n",
       "6   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1134   \n",
       "7   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1084   \n",
       "8   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1154   \n",
       "9   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1162   \n",
       "10  a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1132   \n",
       "11  a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1122   \n",
       "12  a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1142   \n",
       "13  a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1152   \n",
       "14  a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1144   \n",
       "\n",
       "                          name  \n",
       "0   Cooperative Education Prog  \n",
       "1   Cooperative Education Prog  \n",
       "2   Cooperative Education Prog  \n",
       "3   Cooperative Education Prog  \n",
       "4   Cooperative Education Prog  \n",
       "5   Cooperative Education Prog  \n",
       "6   Cooperative Education Prog  \n",
       "7   Cooperative Education Prog  \n",
       "8   Cooperative Education Prog  \n",
       "9   Cooperative Education Prog  \n",
       "10  Cooperative Education Prog  \n",
       "11  Cooperative Education Prog  \n",
       "12  Cooperative Education Prog  \n",
       "13  Cooperative Education Prog  \n",
       "14  Cooperative Education Prog  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_offerings.limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2dd43ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uuid: string (nullable = true)\n",
      " |-- facility_code: string (nullable = true)\n",
      " |-- room_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rooms.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd955600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>facility_code</th>\n",
       "      <th>room_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04368a56-c959-3e4b-8b3d-f4cc3538fea5</td>\n",
       "      <td>OFF CAMPUS</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2cc50da3-ef0e-3572-a557-ca44930a0688</td>\n",
       "      <td>0032</td>\n",
       "      <td>0249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ebbf62b4-2ac3-356b-b0fa-7897f4446a17</td>\n",
       "      <td>0032</td>\n",
       "      <td>B101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ed828265-475b-31b4-b9a8-daec2a600449</td>\n",
       "      <td>0032</td>\n",
       "      <td>0549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b277dc8e-bab1-3a12-bc17-48d4a364d297</td>\n",
       "      <td>0032</td>\n",
       "      <td>0349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bab1dd92-c641-3d28-abd5-50c9573c480b</td>\n",
       "      <td>0032</td>\n",
       "      <td>0510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9759cb5f-a7d3-3d0c-b8b3-03910bd0153e</td>\n",
       "      <td>0469</td>\n",
       "      <td>2441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6af80b0b-b3e3-370a-925f-829869f007bc</td>\n",
       "      <td>0469</td>\n",
       "      <td>4411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50322d30-dd8f-3c65-9a75-78c5ff29d62c</td>\n",
       "      <td>0469</td>\n",
       "      <td>2511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b7211db3-303f-3605-bead-237e1f663932</td>\n",
       "      <td>0469</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fcd8990c-8a4d-36e2-b91f-70838750da26</td>\n",
       "      <td>0469</td>\n",
       "      <td>2401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>350c7321-2d4c-3485-8e0c-8005a6f5ac3d</td>\n",
       "      <td>0469</td>\n",
       "      <td>2411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>f4781736-d27f-3902-9095-5b856acb6db3</td>\n",
       "      <td>0469</td>\n",
       "      <td>2340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2285075b-51f6-394d-8ba8-ef068e004edc</td>\n",
       "      <td>0469</td>\n",
       "      <td>1321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>43a08e18-1ab4-397d-83c0-d0e9a0f2588e</td>\n",
       "      <td>0469</td>\n",
       "      <td>1351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uuid facility_code room_code\n",
       "0   04368a56-c959-3e4b-8b3d-f4cc3538fea5    OFF CAMPUS      null\n",
       "1   2cc50da3-ef0e-3572-a557-ca44930a0688          0032      0249\n",
       "2   ebbf62b4-2ac3-356b-b0fa-7897f4446a17          0032      B101\n",
       "3   ed828265-475b-31b4-b9a8-daec2a600449          0032      0549\n",
       "4   b277dc8e-bab1-3a12-bc17-48d4a364d297          0032      0349\n",
       "5   bab1dd92-c641-3d28-abd5-50c9573c480b          0032      0510\n",
       "6   9759cb5f-a7d3-3d0c-b8b3-03910bd0153e          0469      2441\n",
       "7   6af80b0b-b3e3-370a-925f-829869f007bc          0469      4411\n",
       "8   50322d30-dd8f-3c65-9a75-78c5ff29d62c          0469      2511\n",
       "9   b7211db3-303f-3605-bead-237e1f663932          0469      1341\n",
       "10  fcd8990c-8a4d-36e2-b91f-70838750da26          0469      2401\n",
       "11  350c7321-2d4c-3485-8e0c-8005a6f5ac3d          0469      2411\n",
       "12  f4781736-d27f-3902-9095-5b856acb6db3          0469      2340\n",
       "13  2285075b-51f6-394d-8ba8-ef068e004edc          0469      1321\n",
       "14  43a08e18-1ab4-397d-83c0-d0e9a0f2588e          0469      1351"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rooms.limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "924a7b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uuid: string (nullable = true)\n",
      " |-- course_uuid: string (nullable = true)\n",
      " |-- term_code: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "course_offerings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "803ef87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>course_uuid</th>\n",
       "      <th>term_code</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344b3ebe-da7e-314c-83ed-9425269695fd</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1092</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f718e6cd-33f0-3c14-a9a6-834d9c3610a8</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1082</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ea3b717c-d66b-30dc-8b37-964d9688295f</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1172</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>075da420-5f49-3dd0-93df-13e3c152e1b1</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1114</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2b4e216d-a728-3713-8c7c-19afffc6b2fd</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1104</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>87966a7b-f676-33d0-83d2-acdb67da6790</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1112</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ff511882-5eab-3e7b-a89f-8fbfd1906127</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1134</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b3e26604-fe6e-30df-bc91-b5fa57717a7e</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1084</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e100d196-5e82-32e4-80e9-ac45c07a498c</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1154</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>76b9c458-d3c2-38c4-951f-69b6900bd7fe</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1162</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2cd95315-cc90-33d6-9670-6d4eaddb7104</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1132</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b729bdbf-c272-3d36-ba1b-b428217b037b</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1122</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>c94b0026-46e5-3183-9e02-f0d8616b020e</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1142</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>e6fe4acb-9375-3b46-9d16-6d6ae716d80a</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1152</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>73eb2c88-a7c0-36db-872f-b2fc0c1c956d</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1144</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uuid  \\\n",
       "0   344b3ebe-da7e-314c-83ed-9425269695fd   \n",
       "1   f718e6cd-33f0-3c14-a9a6-834d9c3610a8   \n",
       "2   ea3b717c-d66b-30dc-8b37-964d9688295f   \n",
       "3   075da420-5f49-3dd0-93df-13e3c152e1b1   \n",
       "4   2b4e216d-a728-3713-8c7c-19afffc6b2fd   \n",
       "5   87966a7b-f676-33d0-83d2-acdb67da6790   \n",
       "6   ff511882-5eab-3e7b-a89f-8fbfd1906127   \n",
       "7   b3e26604-fe6e-30df-bc91-b5fa57717a7e   \n",
       "8   e100d196-5e82-32e4-80e9-ac45c07a498c   \n",
       "9   76b9c458-d3c2-38c4-951f-69b6900bd7fe   \n",
       "10  2cd95315-cc90-33d6-9670-6d4eaddb7104   \n",
       "11  b729bdbf-c272-3d36-ba1b-b428217b037b   \n",
       "12  c94b0026-46e5-3183-9e02-f0d8616b020e   \n",
       "13  e6fe4acb-9375-3b46-9d16-6d6ae716d80a   \n",
       "14  73eb2c88-a7c0-36db-872f-b2fc0c1c956d   \n",
       "\n",
       "                             course_uuid  term_code  \\\n",
       "0   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1092   \n",
       "1   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1082   \n",
       "2   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1172   \n",
       "3   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1114   \n",
       "4   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1104   \n",
       "5   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1112   \n",
       "6   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1134   \n",
       "7   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1084   \n",
       "8   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1154   \n",
       "9   a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1162   \n",
       "10  a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1132   \n",
       "11  a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1122   \n",
       "12  a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1142   \n",
       "13  a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1152   \n",
       "14  a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de       1144   \n",
       "\n",
       "                          name  \n",
       "0   Cooperative Education Prog  \n",
       "1   Cooperative Education Prog  \n",
       "2   Cooperative Education Prog  \n",
       "3   Cooperative Education Prog  \n",
       "4   Cooperative Education Prog  \n",
       "5   Cooperative Education Prog  \n",
       "6   Cooperative Education Prog  \n",
       "7   Cooperative Education Prog  \n",
       "8   Cooperative Education Prog  \n",
       "9   Cooperative Education Prog  \n",
       "10  Cooperative Education Prog  \n",
       "11  Cooperative Education Prog  \n",
       "12  Cooperative Education Prog  \n",
       "13  Cooperative Education Prog  \n",
       "14  Cooperative Education Prog  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_offerings.limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd4ea1",
   "metadata": {},
   "source": [
    "## Recap: About this database\n",
    "\n",
    "You will notice that there are several more tables in the uw-madision-courses folder than there are read in above. This so that you will have a chance to practice your own custom joins and learn about the relationships between a real database work. Sometimes we don't know how they are related and we need to figure it out! I'll save that for the HW :) \n",
    "\n",
    "Here is a look at some of the important variables we can use to join our tables:\n",
    "\n",
    " - course_offerings: uuid, course_uuid, term_code, name\n",
    " - instructors: id, name\n",
    " - schedules: uuid\n",
    " - sections: uuid, course_offering_uuid,room_uuid, schedule_uuid\n",
    " - teachings: instructor_id, section_uuid\n",
    " - courses: uuid\n",
    " - grade_distributions: course_offering_uuid,section_number\n",
    " - rooms: uuid, facility_code, room_code\n",
    " - subjects: code\n",
    " - subject_memberships: subject_code, course_offering_uuid\n",
    " \n",
    " **Source:** https://www.kaggle.com/Madgrades/uw-madison-courses\n",
    " \n",
    "So alright, let's use this information to discover some insights from this data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e981e",
   "metadata": {},
   "source": [
    "## 1a. Can you assign the room numbers to each section of each course?\n",
    "\n",
    "Show only the rooms uuid, facility code, room number, term code and the name of the course from the course_offerings table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d16bd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+\n",
      "|term_code|                name|           room_uuid|\n",
      "+---------+--------------------+--------------------+\n",
      "|     1092|Cooperative Educa...|                null|\n",
      "|     1082|Cooperative Educa...|                null|\n",
      "|     1172|Cooperative Educa...|04368a56-c959-3e4...|\n",
      "|     1172|Cooperative Educa...|                null|\n",
      "|     1172|Cooperative Educa...|                null|\n",
      "|     1172|Cooperative Educa...|04368a56-c959-3e4...|\n",
      "|     1114|Cooperative Educa...|04368a56-c959-3e4...|\n",
      "|     1114|Cooperative Educa...|                null|\n",
      "|     1104|Cooperative Educa...|                null|\n",
      "|     1104|Cooperative Educa...|04368a56-c959-3e4...|\n",
      "|     1112|Cooperative Educa...|                null|\n",
      "|     1134|Cooperative Educa...|04368a56-c959-3e4...|\n",
      "|     1134|Cooperative Educa...|04368a56-c959-3e4...|\n",
      "|     1134|Cooperative Educa...|                null|\n",
      "|     1084|Cooperative Educa...|                null|\n",
      "|     1084|Cooperative Educa...|04368a56-c959-3e4...|\n",
      "|     1154|Cooperative Educa...|                null|\n",
      "|     1154|Cooperative Educa...|04368a56-c959-3e4...|\n",
      "|     1154|Cooperative Educa...|04368a56-c959-3e4...|\n",
      "|     1154|Cooperative Educa...|                null|\n",
      "+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "first_join = sections.join(course_offerings, sections.course_offering_uuid == course_offerings.uuid, how=\"inner\").select(['term_code', 'name', 'room_uuid'])\n",
    "first_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86881092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------------+---------+---------+------------------------------+\n",
      "|room_uuid                           |facility_code|room_code|term_code|name                          |\n",
      "+------------------------------------+-------------+---------+---------+------------------------------+\n",
      "|85d48cdb-8a44-35ec-a5b6-fdd920aef550|0545         |4004     |1094     |Intro to Speech Composition   |\n",
      "|eda7ac38-2d95-3114-b675-c49966779d6d|0545         |4046     |1102     |Intro to Speech Composition   |\n",
      "|026d4b38-9cc3-361d-af8d-ef162119f51e|0140         |2170     |1162     |Intro Financial Accounting    |\n",
      "|913b30ca-3e8f-393b-bec9-6683abc6beec|0046         |5106     |1084     |Intro to Cultures of Asia     |\n",
      "|babe81ae-64cc-3b30-b6ee-cb0f21c79c88|0070         |0125     |1094     |General Microbiology          |\n",
      "|34d2c6bf-a685-3154-810c-f35db51bd417|0469         |3650     |1172     |Principles-Microeconomics     |\n",
      "|5acfb8fa-8860-34bf-b551-52c7730f0a7e|0046         |6314     |1134     |Principles-Microeconomics     |\n",
      "|ce8bbeed-5bf1-3044-b7f1-3310d5d99e58|0482         |0378     |1082     |Principles-Microeconomics     |\n",
      "|643ec16b-ffa8-3402-8aa8-feeaa068565e|0046         |6101     |1094     |Principles-Microeconomics     |\n",
      "|21602659-e0a6-390b-9b1a-23e9d696d746|0050         |0052     |1094     |Principles-Microeconomics     |\n",
      "|050bf5dc-0068-3a37-b5fc-2c27c1992cc4|0048         |B203     |1092     |Human Language                |\n",
      "|effa4252-8506-386c-82f9-f4530396abd2|0046         |6210     |1092     |Human Language                |\n",
      "|38abcc33-c69a-373b-872b-ad42d866fa42|0482         |0215     |1082     |Human Language                |\n",
      "|7426f3f3-5811-33a4-ad7c-ffac37ff246e|0056         |0214     |1114     |Human Language                |\n",
      "|afe4870f-fce8-316e-b6b6-6dec739f8cdd|0482         |0475     |1074     |Human Language                |\n",
      "|a54eeeb7-baed-35b4-ab83-c58c7c4523a3|0050         |0053     |1132     |Animal Biology                |\n",
      "|ad9fcc3c-069c-397b-9173-2a2f0d5399d3|0402         |0119     |1112     |Animal Biology                |\n",
      "|c99bd3a7-b8f9-3da5-b071-3e7bafae3398|0402         |0553     |1072     |Animal Biology                |\n",
      "|050989c6-d81a-34ad-bf84-7f635bf49398|0482         |0382     |1152     |First Semester Norwegian      |\n",
      "|0d10d595-ea84-3e4c-a591-11ecadb78eab|0400         |0234     |1074     |Introduction to Philosophy    |\n",
      "|5b3667e7-369b-3677-8340-b7220d009f2c|0400         |0434     |1084     |Introduction to Philosophy    |\n",
      "|e9f73325-cab9-3cf9-a2fe-7c954a0c80b2|0469         |2451     |1112     |The Musical Experience        |\n",
      "|050989c6-d81a-34ad-bf84-7f635bf49398|0482         |0382     |1072     |First Semester French         |\n",
      "|61449143-1ddb-3478-b0ab-f88c93cdf4f2|0482         |0587     |1144     |First Semester French         |\n",
      "|fce290a4-ed7d-30cf-ab0a-e4c64ecfce09|0469         |2125     |1094     |Amer Hist to Civil War Era    |\n",
      "|6b7d01f9-d072-3de9-a508-66ab5c7d0741|0545         |4041     |1112     |Amer Hist to Civil War Era    |\n",
      "|2865d1c4-3b34-3a05-a561-ac682349b30c|0046         |6322     |1152     |Intro to International Studies|\n",
      "|a4436f44-ffe7-391a-9da5-c62fe309cfdf|0482         |0205     |1072     |First Semester Italian        |\n",
      "|60d0fe52-9c1d-3696-910a-5473eb79c1b4|0046         |5206     |1102     |Archaeology & Prehist World   |\n",
      "|de955b71-9e71-3e98-b321-2ae35dad4d80|0482         |0223     |1144     |Second Semester French        |\n",
      "+------------------------------------+-------------+---------+---------+------------------------------+\n",
      "only showing top 30 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "second_join = first_join.join(rooms, first_join.room_uuid == rooms.uuid, how=\"inner\").select(['room_uuid', 'facility_code','room_code','term_code', 'name',]).dropDuplicates()\n",
    "second_join.show(30,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22396beb",
   "metadata": {},
   "source": [
    "## 1b. Now show same output as above but for only facility number 0469 (facility_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a88e706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------------+---------+---------+------------------------------+\n",
      "|room_uuid                           |facility_code|room_code|term_code|name                          |\n",
      "+------------------------------------+-------------+---------+---------+------------------------------+\n",
      "|34d2c6bf-a685-3154-810c-f35db51bd417|0469         |3650     |1172     |Principles-Microeconomics     |\n",
      "|e9f73325-cab9-3cf9-a2fe-7c954a0c80b2|0469         |2451     |1112     |The Musical Experience        |\n",
      "|fce290a4-ed7d-30cf-ab0a-e4c64ecfce09|0469         |2125     |1094     |Amer Hist to Civil War Era    |\n",
      "|d90fd659-4ffa-3536-87b1-381855199a0f|0469         |2611     |1092     |Amer Hist-Civil War-Present   |\n",
      "|d90fd659-4ffa-3536-87b1-381855199a0f|0469         |2611     |1104     |The Symphony                  |\n",
      "|00593bf2-b562-3482-9bb3-e2b5e7e00a16|0469         |1101     |1082     |Foundations of Contemp Art    |\n",
      "|2da69d83-787a-3b03-a82b-133026765ef1|0469         |2251     |1182     |Acad Reading and Vocab Skills |\n",
      "|da446c18-f321-3dc7-809b-c8fdc0ab3d78|0469         |2131     |1104     |Modern Europe 1500-1815       |\n",
      "|350c7321-2d4c-3485-8e0c-8005a6f5ac3d|0469         |2411     |1102     |Musica Practica 1             |\n",
      "|9a15c09e-57d8-3658-ae72-aae5ffdef108|0469         |2637     |1182     |Myth and Literature           |\n",
      "|0fabcc36-e3c1-32c3-99a9-c7c6ae53e992|0469         |1221     |1132     |Black Music&Am Cultrl Hist    |\n",
      "|c731d9db-3bc4-3436-a5fd-7954098d3193|0469         |2619     |1162     |Asian Am Hist:Movmnt&Dislocatn|\n",
      "|0fabcc36-e3c1-32c3-99a9-c7c6ae53e992|0469         |1221     |1182     |Calc with Algebra & Trig I    |\n",
      "|78453f15-be53-3168-a90d-47e0da0a4046|0469         |2211     |1134     |The Historian's Craft         |\n",
      "|b7211db3-303f-3605-bead-237e1f663932|0469         |1341     |1094     |Concert Band                  |\n",
      "|ec82b0ac-f6c3-3499-9202-b7d10b4eb11b|0469         |2631     |1152     |Intro to College Composition  |\n",
      "|0fabcc36-e3c1-32c3-99a9-c7c6ae53e992|0469         |1221     |1104     |Introduction to Art           |\n",
      "|c731d9db-3bc4-3436-a5fd-7954098d3193|0469         |2619     |1102     |Introduction to Philosophy    |\n",
      "|53f46826-6db2-326c-b3a3-00d01f86300f|0469         |2653     |1162     |Amer Hist-Civil War-Present   |\n",
      "|350c7321-2d4c-3485-8e0c-8005a6f5ac3d|0469         |2411     |1164     |Intro-Mus Cult of the World   |\n",
      "|34d2c6bf-a685-3154-810c-f35db51bd417|0469         |3650     |1122     |Intro-Internatl Relations     |\n",
      "|92c7d363-5605-3323-a6cc-2aa705f21342|0469         |2101     |1082     |Human Dev: Ed Effectiveness   |\n",
      "|1086dddd-6b2d-34da-a2b6-3a35a4cd856a|0469         |2650     |1142     |Modern Europe 1500-1815       |\n",
      "|fce290a4-ed7d-30cf-ab0a-e4c64ecfce09|0469         |2125     |1122     |The Information Society       |\n",
      "|b7211db3-303f-3605-bead-237e1f663932|0469         |1341     |1164     |Concert Band                  |\n",
      "|2285075b-51f6-394d-8ba8-ef068e004edc|0469         |1321     |1074     |University Band               |\n",
      "|43a08e18-1ab4-397d-83c0-d0e9a0f2588e|0469         |1351     |1104     |Concert Choir                 |\n",
      "|b7211db3-303f-3605-bead-237e1f663932|0469         |1341     |1142     |All-Univ String Orchestra     |\n",
      "|763813ce-ff70-3c69-8c78-f2a34fb20402|0469         |2521     |1102     |Intro-Mus Cult of the World   |\n",
      "|2b57b421-6c9f-3d88-9299-21b41c693446|0469         |2261     |1174     |Academic Writing II           |\n",
      "+------------------------------------+-------------+---------+---------+------------------------------+\n",
      "only showing top 30 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "only_facility = second_join.filter(second_join.facility_code == \"0469\")\n",
    "only_facility.show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08322aa",
   "metadata": {},
   "source": [
    "## 2. Count how many sections are offered for each subject for each facility\n",
    "\n",
    "*Note: this will involve a groupby*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4be7d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|facility_code|count|\n",
      "+-------------+-----+\n",
      "|         0469| 2671|\n",
      "|         0452|    4|\n",
      "|         0047|  863|\n",
      "|         0407|  146|\n",
      "|         0545|  988|\n",
      "|         0153|   16|\n",
      "|         0031|   72|\n",
      "|         0140|  535|\n",
      "|         0430|    3|\n",
      "|         0080|   15|\n",
      "|         0021|   13|\n",
      "|         0060|   50|\n",
      "|         0032|  213|\n",
      "|         0576|    2|\n",
      "|         0082|   22|\n",
      "|         0520|   23|\n",
      "|         0503|    4|\n",
      "|         0084|   52|\n",
      "|         0055|  566|\n",
      "|         0482| 2644|\n",
      "+-------------+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "second_join.groupBy('facility_code').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0e8ff7",
   "metadata": {},
   "source": [
    "## 3. What are the hardest classes?\n",
    "\n",
    "Let's see if we can figure out which classes are the hardest by seeing how many students failed. Note that you will first need to aggregate the grades table by the course uuid to include all sections. Show the name of the course as well that you will need to get from the course_offering table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8bed425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+--------------+\n",
      "|course_name                 |total_failures|\n",
      "+----------------------------+--------------+\n",
      "|Calc--Functns of Variables  |72            |\n",
      "|Animal Biology              |70            |\n",
      "|Calculus&Analytic Geometry  |67            |\n",
      "|Calculus&Analytic Geometry 1|64            |\n",
      "|Calculus&Analytic Geometry  |63            |\n",
      "|Calculus&Analytic Geometry  |59            |\n",
      "|Calculus&Analytic Geometry  |58            |\n",
      "|Calculus&Analytic Geometry 1|57            |\n",
      "|Animal Biology              |56            |\n",
      "|Animal Biology              |54            |\n",
      "|Animal Biology              |53            |\n",
      "|Calculus&Analytic Geometry  |53            |\n",
      "|Animal Biology              |52            |\n",
      "|Calculus&Analytic Geometry  |52            |\n",
      "|Intro Organic Chemistry     |52            |\n",
      "|Intro Organic Chemistry     |51            |\n",
      "|Calculus                    |50            |\n",
      "|Calculus&Analytic Geometry  |49            |\n",
      "|Intro Organic Chemistry     |49            |\n",
      "|Intro Organic Chemistry     |49            |\n",
      "|Calculus&Analytic Geometry  |48            |\n",
      "|Calculus&Analytic Geometry  |48            |\n",
      "|Calc--Functns of Variables  |48            |\n",
      "|Linear Alg & Diff Equations |48            |\n",
      "|Animal Biology              |47            |\n",
      "|Intro Organic Chemistry     |47            |\n",
      "|Calculus&Analytic Geometry  |46            |\n",
      "|General Chemistry           |45            |\n",
      "|Calculus&Analytic Geometry  |45            |\n",
      "|Calculus&Analytic Geometry 2|45            |\n",
      "+----------------------------+--------------+\n",
      "only showing top 30 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum, desc\n",
    "\n",
    "course_failures = grade_distributions.groupBy('course_offering_uuid').agg(\n",
    "\n",
    "    sum(col('f_count')).alias('total_failures'))\n",
    "\n",
    "hardest_classes = course_failures.join(\n",
    "    course_offerings,\n",
    "    course_failures.course_offering_uuid == course_offerings.uuid,\n",
    "    how='inner').select(course_offerings['name'].alias('course_name'),\n",
    "    col('total_failures'))\n",
    "\n",
    "hardest_classes.orderBy(desc('total_failures')).show(30, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd724ff",
   "metadata": {},
   "source": [
    "## Challenge Question: Automating data entry errors\n",
    "\n",
    "We see in the dataframe below that there are several typos of various animal names. If this was a large database of several millions of records, correcting these errors would be way too labor intensive. How can we automate correcting these errors?\n",
    "\n",
    "*Hint: Leven...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9595370f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+\n",
      "|      Animal|age|\n",
      "+------------+---+\n",
      "|      Monkey| 10|\n",
      "|      Monkay| 36|\n",
      "|        Mnky|123|\n",
      "|    Elephant| 48|\n",
      "|     Elefant| 16|\n",
      "|    Ellafant|  1|\n",
      "|Hippopotamus| 48|\n",
      "| Hipopotamus| 16|\n",
      "|       Hippo|  1|\n",
      "+------------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "values = [('Monkey',10),('Monkay',36),('Mnky',123), \\\n",
    "          ('Elephant',48),('Elefant',16),('Ellafant',1), \\\n",
    "          ('Hippopotamus',48),('Hipopotamus',16),('Hippo',1)]\n",
    "zoo = spark.createDataFrame(values,['Animal','age'])\n",
    "zoo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88820e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
