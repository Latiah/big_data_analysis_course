{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00000-a579b3bd-6eb6-4445-8bb9-82fb1dc1e072",
        "deepnote_cell_type": "markdown",
        "id": "TseOmaeVepJP"
      },
      "source": [
        "# PySpark\n",
        "\n",
        "![Logo](https://github.com/pnavaro/big-data/blob/master/notebooks/images/apache_spark_logo.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00001-bf31e048-ace9-4993-8da2-5f1af4015c57",
        "deepnote_cell_type": "markdown",
        "id": "7MCoeao9epJV"
      },
      "source": [
        "- [Apache Spark](https://spark.apache.org) was first released in 2014.\n",
        "- It was originally developed by [Matei Zaharia](http://people.csail.mit.edu/matei) as a class project, and later a PhD dissertation, at University of California, Berkeley.\n",
        "- Spark is written in [Scala](https://www.scala-lang.org).\n",
        "- All images come from [Databricks](https://databricks.com/product/getting-started-guide)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00002-bb8dce6d-d8e9-486b-818d-f6dcc250b446",
        "deepnote_cell_type": "markdown",
        "id": "azcYAKk-epJX"
      },
      "source": [
        "- Apache Spark is a fast and general-purpose cluster computing system.\n",
        "- It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs.\n",
        "- Spark can manage \"big data\" collections with a small set of high-level primitives like `map`, `filter`, `groupby`, and `join`.  With these common patterns we can often handle computations that are more complex than map, but are still structured.\n",
        "- It also supports a rich set of higher-level tools including [Spark SQL](https://spark.apache.org/docs/latest/sql-programming-guide.html) for SQL and structured data processing, [MLlib](https://spark.apache.org/docs/latest/ml-guide.html) for machine learning, [GraphX](https://spark.apache.org/docs/latest/graphx-programming-guide.html) for graph processing, and Spark Streaming."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00003-d67dd6f1-d704-4caa-81cf-5a9071b62f17",
        "deepnote_cell_type": "markdown",
        "id": "Ps7SkNSEepJZ"
      },
      "source": [
        "## Resilient distributed datasets\n",
        "\n",
        "- The fundamental abstraction of Apache Spark is a read-only, parallel, distributed, fault-tolerent collection called a resilient distributed datasets (RDD).\n",
        "- RDDs behave a bit like Python collections (e.g. lists).\n",
        "- When working with Apache Spark we iteratively apply functions to every item of these collections in parallel to produce *new* RDDs.\n",
        "- The data is distributed across nodes in a cluster of computers.\n",
        "- Functions implemented in Spark can work in parallel across elements of the collection.\n",
        "- The  Spark framework allocates data and processing to different nodes, without any intervention from the programmer.\n",
        "- RDDs automatically rebuilt on machine failure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00004-befe75de-d238-405e-81e7-38cedbf082ce",
        "deepnote_cell_type": "markdown",
        "id": "Eu2f4twKepJc"
      },
      "source": [
        "## Lifecycle of a Spark Program\n",
        "\n",
        "1. Create some input RDDs from external data or parallelize a collection in your driver program.\n",
        "2. Lazily transform them to define new RDDs using transformations like `filter()` or `map()`\n",
        "3. Ask Spark to cache() any intermediate RDDs that will need to be reused.\n",
        "4. Launch actions such as count() and collect() to kick off a parallel computation, which is then optimized and executed by Spark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00005-7b21b99e-f856-4c8e-9be8-3c9e9f4e9630",
        "deepnote_cell_type": "markdown",
        "id": "dHTv00_bepJd"
      },
      "source": [
        "## Operations on Distributed Data\n",
        "\n",
        "- Two types of operations: **transformations** and **actions**\n",
        "- Transformations are *lazy* (not computed immediately)\n",
        "- Transformations are executed when an action is run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00006-d114d429-bb93-4c93-affc-216589f7db5e",
        "deepnote_cell_type": "markdown",
        "id": "IjykGZWnepJe"
      },
      "source": [
        "## [Transformations](https://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations) (lazy)\n",
        "\n",
        "```\n",
        "map() flatMap()\n",
        "filter()\n",
        "mapPartitions() mapPartitionsWithIndex()\n",
        "sample()\n",
        "union() intersection() distinct()\n",
        "groupBy() groupByKey()\n",
        "reduceBy() reduceByKey()\n",
        "sortBy() sortByKey()\n",
        "join()\n",
        "cogroup()\n",
        "cartesian()\n",
        "pipe()\n",
        "coalesce()\n",
        "repartition()\n",
        "partitionBy()\n",
        "...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00007-c19d8245-7c9f-407b-8518-0cdbb557be79",
        "deepnote_cell_type": "markdown",
        "id": "rOn-vwfGepJi"
      },
      "source": [
        "## [Actions](https://spark.apache.org/docs/latest/rdd-programming-guide.html#actions)\n",
        "\n",
        "```\n",
        "reduce()\n",
        "collect()\n",
        "count()\n",
        "first()\n",
        "take()\n",
        "takeSample()\n",
        "saveToCassandra()\n",
        "takeOrdered()\n",
        "saveAsTextFile()\n",
        "saveAsSequenceFile()\n",
        "saveAsObjectFile()\n",
        "countByKey()\n",
        "foreach()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00008-385816d2-d5dd-4556-a0ec-2bbc0d0f54dc",
        "deepnote_cell_type": "markdown",
        "id": "FuZ1QjYwepJk"
      },
      "source": [
        "## Python API\n",
        "\n",
        "PySpark uses Py4J that enables Python programs to dynamically access Java objects.\n",
        "\n",
        "![PySpark Internals](https://github.com/pnavaro/big-data/blob/master/notebooks/images/YlI8AqEl.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00009-f66ff6fd-edde-4c4c-bfa1-ba0d1d96ba97",
        "deepnote_cell_type": "markdown",
        "id": "joYETQsSepJl"
      },
      "source": [
        "## The `SparkContext` class\n",
        "\n",
        "- When working with Apache Spark we invoke methods on an object which is an instance of the `pyspark.SparkContext` context.\n",
        "\n",
        "- Typically, an instance of this object will be created automatically for you and assigned to the variable `sc`.\n",
        "\n",
        "- The `parallelize` method in `SparkContext` can be used to turn any ordinary Python collection into an RDD;\n",
        "    - normally we would create an RDD from a large file or an HBase table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00010-a1e30157-0efd-490d-8b63-459dfb96da8a",
        "deepnote_cell_type": "markdown",
        "id": "MOO8pH3iepJm"
      },
      "source": [
        "## First example\n",
        "\n",
        "PySpark isn't on sys.path by default, but that doesn't mean it can't be used as a regular library. You can address this by either symlinking pyspark into your site-packages, or adding pyspark to sys.path at runtime. [findspark](https://github.com/minrk/findspark) does the latter.\n",
        "\n",
        "We have a spark context sc to use with a tiny local spark cluster with 4 nodes (will work just fine on a multicore machine)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cell_id": "00012-8698152c-385e-4d22-ae56-408429b08600",
        "deepnote_cell_type": "code",
        "execution_millis": 4,
        "execution_start": 1606208122779,
        "id": "RvBvcPCsepJn",
        "output_cleared": false,
        "source_hash": "a22d9657"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Library/Frameworks/Python.framework/Versions/3.13/bin/python3'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os, sys\n",
        "sys.executable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "cell_id": "00013-7e179656-f878-4ef7-bfc5-4683fd92851d",
        "deepnote_cell_type": "code",
        "execution_millis": 1,
        "execution_start": 1606208260172,
        "id": "qKGv5gJVepJp",
        "output_cleared": false,
        "source_hash": "a04577ae"
      },
      "outputs": [],
      "source": [
        "#os.environ[\"SPARK_HOME\"] = \"/opt/spark-3.0.1-bin-hadoop2.7\"\n",
        "os.environ[\"PYSPARK_PYTHON\"] = sys.executable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cell_id": "00014-f661aeba-0a4e-489c-93b7-034ee40d1ef4",
        "deepnote_cell_type": "code",
        "execution_millis": 7637,
        "execution_start": 1606208269332,
        "id": "OBl1KVwcepJq",
        "output_cleared": false,
        "source_hash": "73659aa7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Using incubator modules: jdk.incubator.vector\n",
            "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "25/11/18 18:12:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "25/11/18 18:12:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
            "25/11/18 18:12:44 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
            "25/11/18 18:12:44 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
            "25/11/18 18:12:44 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
            "25/11/18 18:12:44 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n"
          ]
        }
      ],
      "source": [
        "import pyspark\n",
        "\n",
        "sc = pyspark.SparkContext(master=\"local[*]\", appName=\"FirstExample\").getOrCreate()\n",
        "sc.setLogLevel(\"ERROR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#sc.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "cell_id": "00015-bf748379-3532-453e-8058-f4fc6531a830",
        "deepnote_cell_type": "code",
        "execution_millis": 5,
        "execution_start": 1606208288902,
        "id": "5oeERBbrepJr",
        "output_cleared": false,
        "source_hash": "3831e90d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<SparkContext master=local[*] appName=FirstExample>\n"
          ]
        }
      ],
      "source": [
        "print(sc) # it is like a Pool Processor executor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00016-192e38d9-530b-4b44-82f2-0e98ab5d8379",
        "deepnote_cell_type": "markdown",
        "id": "Dh_BwkCHepJs"
      },
      "source": [
        "## Create your first RDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7]"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = list(range(8))\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "cell_id": "00017-6079893b-b1de-4a98-91ee-cbc10b34cb56",
        "deepnote_cell_type": "code",
        "execution_millis": 549,
        "execution_start": 1606208314201,
        "id": "mKeWSz-6epJs",
        "output_cleared": false,
        "source_hash": "27883792"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7]"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "rdd = sc.parallelize(data) # create collection\n",
        "rdd.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00018-3d4cb001-a63e-4efa-a375-656a819b62f7",
        "deepnote_cell_type": "markdown",
        "id": "z1pHV-AyepJs"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Create a file `./Datasets/WhoAreWe.txt` with the text bellow. Read and load it into a RDD with the `textFile` spark function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The African Institute for Mathematical Sciences (AIMS) is a pan-African network of Centres of Excellence for postgraduate training in mathematical sciences, research, and public engagement in Science, Technology, Engineering, and Mathematics. Founded in 2003 in South Africa by acclaimed physicist Prof Neil Turok and later replicated in Senegal, Ghana, Cameroon and Rwanda, AIMS is leading Africa’s socio-economic transformation through:\n",
        "\n",
        "Innovative scientific training (the development of human capital);\n",
        "\n",
        "Technological advances and cutting-edge scientific discoveries; and\n",
        "\n",
        "Public engagement for the continent’s scientific emergence.\n",
        "\n",
        "Africa’s youth are at the heart of the AIMS innovation and transformation ecosystem which consists of a set of academic and non-academic programs expertly tailored to provide AIMS learners with a unique postgraduate training experience on the continent.\n",
        "\n",
        "AIMS offers a Master’s in mathematical sciences, including a co-operative option with a direct link to industry, the African Master’s in Machine Intelligence (AMMI), as well as research programs, with over 100 researchers conducting studies across the network. In addition to the AIMS Industry Initiative and a gender-responsive Teacher Training Program currently implemented in Cameroon and Rwanda, AIMS equally created two critical initiatives: Quantum Leap Africa, a think tank looking into the coming quantum revolution and the Next Einstein Forum to propel Africa on to the global scientific stage. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now read the file using "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read `textFile` from the `Datasets/` folder using the function `textFile`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO\n",
        "# rdd =  uncomment and write your code here.\n",
        "rdd_file = sc.textFile(\"Datasets/WhoAreWe.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00020-f8161a29-5442-40bc-b3ad-314ac079b925",
        "deepnote_cell_type": "markdown",
        "id": "eiKXwbzVepJt"
      },
      "source": [
        "### Collect\n",
        "\n",
        "Action / To Driver: Return all items in the RDD to the driver in a single list\n",
        "\n",
        "![](https://github.com/pnavaro/big-data/blob/master/notebooks/images/DUO6ygB.png?raw=1)\n",
        "\n",
        "Source: https://i.imgur.com/DUO6ygB.png\n",
        "\n",
        "### Exercise\n",
        "\n",
        "Collect the text you read before from the `WhoAreWe.txt`file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The African Institute for Mathematical Sciences (AIMS) is a pan-African network of Centres of Excellence for postgraduate training in mathematical sciences, research, and public engagement in Science, Technology, Engineering, and Mathematics. Founded in 2003 in South Africa by acclaimed physicist Prof Neil Turok and later replicated in Senegal, Ghana, Cameroon and Rwanda, AIMS is leading Africa’s socio-economic transformation through:',\n",
              " '',\n",
              " 'Innovative scientific training (the development of human capital);',\n",
              " '',\n",
              " 'Technological advances and cutting-edge scientific discoveries; and',\n",
              " '',\n",
              " 'Public engagement for the continent’s scientific emergence.',\n",
              " '',\n",
              " 'Africa’s youth are at the heart of the AIMS innovation and transformation ecosystem which consists of a set of academic and non-academic programs expertly tailored to provide AIMS learners with a unique postgraduate training experience on the continent.',\n",
              " '',\n",
              " 'AIMS offers a Master’s in mathematical sciences, including a co-operative option with a direct link to industry, the African Master’s in Machine Intelligence (AMMI), as well as research programs, with over 100 researchers conducting studies across the network. In addition to the AIMS Industry Initiative and a gender-responsive Teacher Training Program currently implemented in Cameroon and Rwanda, AIMS equally created two critical initiatives: Quantum Leap Africa, a think tank looking into the coming quantum revolution and the Next Einstein Forum to propel Africa on to the global scientific stage. ']"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd_file.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00021-88914dd9-d7ed-435c-988d-b333620a63f9",
        "deepnote_cell_type": "markdown",
        "id": "K7Bf6BKHepJu"
      },
      "source": [
        "### Map\n",
        "\n",
        "Transformation / Narrow: Return a new RDD by applying a function to each element of this RDD\n",
        "\n",
        "![](https://github.com/pnavaro/big-data/blob/master/notebooks/images/PxNJf0U.png?raw=1)\n",
        "\n",
        "Source: http://i.imgur.com/PxNJf0U.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "cell_id": "00022-e19738f1-5568-4e01-a918-31f95720f79a",
        "deepnote_cell_type": "code",
        "execution_millis": 2412,
        "execution_start": 1605183503558,
        "id": "DMaj43GKepJu",
        "output_cleared": false,
        "source_hash": "8210a3cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0, 1, 4, 9, 16, 25, 36, 49]"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd = sc.parallelize(list(range(8)))\n",
        "rdd.map(lambda x: x ** 2).collect() # Square each element"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def calculate(x):\n",
        "    return(x**2)\n",
        "calculate(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n"
          ]
        }
      ],
      "source": [
        "f = lambda x: x**2\n",
        "print(f(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7]"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd = sc.parallelize(list(range(8)))\n",
        "rdd.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = list(range(21))\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 4,\n",
              " 9,\n",
              " 16,\n",
              " 25,\n",
              " 36,\n",
              " 49,\n",
              " 64,\n",
              " 81,\n",
              " 100,\n",
              " 121,\n",
              " 144,\n",
              " 169,\n",
              " 196,\n",
              " 225,\n",
              " 256,\n",
              " 289,\n",
              " 324,\n",
              " 361,\n",
              " 400]"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(map(lambda l: l**2, a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd.getNumPartitions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00023-096cde31-3814-4827-a025-e528f1021b55",
        "deepnote_cell_type": "markdown",
        "id": "Ges3znO1epJv"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Replace the lambda function by a function that contains a pause (sleep(1)) and check if the `map` operation is parallelized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "#f = lambda x: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00024-0a7d639a-570b-49d3-a71a-7330ec203bc8",
        "deepnote_cell_type": "markdown",
        "id": "eAOfDfvBepJv"
      },
      "source": [
        "### Filter\n",
        "\n",
        "Transformation / Narrow: Return a new RDD containing only the elements that satisfy a predicate\n",
        "\n",
        "![](https://github.com/pnavaro/big-data/blob/master/notebooks/images/GFyji4U.png?raw=1)\n",
        "Source: http://i.imgur.com/GFyji4U.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "cell_id": "00025-9893a281-e7fd-49e4-880e-c18c223437e2",
        "deepnote_cell_type": "code",
        "id": "g6t-uJi0epJv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 2, 4, 6]"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Select only the even elements\n",
        "rdd.filter(lambda x: x % 2 == 0).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(filter(lambda a: a%2 == 0, a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 5, 10, 15, 20]"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(filter(lambda a: a%5 == 0, a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19]"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(filter(lambda a: a%2 != 0, a))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00026-c2044f27-66c2-49e4-a2c3-1551769fc2fe",
        "deepnote_cell_type": "markdown",
        "id": "-GG5SvGGepJw"
      },
      "source": [
        "### FlatMap\n",
        "\n",
        "Transformation / Narrow: Return a new RDD by first applying a function to all elements of this RDD, and then flattening the results\n",
        "\n",
        "![](https://github.com/pnavaro/big-data/blob/master/notebooks/images/TsSUex8.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "cell_id": "00027-eab04ee2-2189-474e-b0ee-7cdf04d51334",
        "deepnote_cell_type": "code",
        "execution_millis": 1423,
        "execution_start": 1606209096798,
        "id": "PjifIDDmepJz",
        "output_cleared": false,
        "source_hash": "ed69af29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 100, 20, 2, 200, 20, 3, 300, 20]"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd = sc.parallelize([1,2,3])\n",
        "rdd.flatMap(lambda x: (x, x*100, 20)).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = 'I am learning big data analysis with python'\n",
        "len(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_text=text.split(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text.split(\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The',\n",
              " 'African',\n",
              " 'Institute',\n",
              " 'for',\n",
              " 'Mathematical',\n",
              " 'Sciences',\n",
              " '(AIMS)',\n",
              " 'is',\n",
              " 'a',\n",
              " 'pan-African',\n",
              " 'network',\n",
              " 'of',\n",
              " 'Centres',\n",
              " 'of',\n",
              " 'Excellence',\n",
              " 'for',\n",
              " 'postgraduate',\n",
              " 'training',\n",
              " 'in',\n",
              " 'mathematical',\n",
              " 'sciences,',\n",
              " 'research,',\n",
              " 'and',\n",
              " 'public',\n",
              " 'engagement',\n",
              " 'in',\n",
              " 'Science,',\n",
              " 'Technology,',\n",
              " 'Engineering,',\n",
              " 'and',\n",
              " 'Mathematics',\n",
              " '',\n",
              " 'Founded',\n",
              " 'in',\n",
              " '2003',\n",
              " 'in',\n",
              " 'South',\n",
              " 'Africa',\n",
              " 'by',\n",
              " 'acclaimed',\n",
              " 'physicist',\n",
              " 'Prof',\n",
              " 'Neil',\n",
              " 'Turok',\n",
              " 'and',\n",
              " 'later',\n",
              " 'replicated',\n",
              " 'in',\n",
              " 'Senegal,',\n",
              " 'Ghana,',\n",
              " 'Cameroon',\n",
              " 'and',\n",
              " 'Rwanda,',\n",
              " 'AIMS',\n",
              " 'is',\n",
              " 'leading',\n",
              " 'Africa’s',\n",
              " 'socio-economic',\n",
              " 'transformation',\n",
              " 'through:',\n",
              " '',\n",
              " 'Innovative',\n",
              " 'scientific',\n",
              " 'training',\n",
              " '(the',\n",
              " 'development',\n",
              " 'of',\n",
              " 'human',\n",
              " 'capital);',\n",
              " '',\n",
              " 'Technological',\n",
              " 'advances',\n",
              " 'and',\n",
              " 'cutting-edge',\n",
              " 'scientific',\n",
              " 'discoveries;',\n",
              " 'and',\n",
              " '',\n",
              " 'Public',\n",
              " 'engagement',\n",
              " 'for',\n",
              " 'the',\n",
              " 'continent’s',\n",
              " 'scientific',\n",
              " 'emergence',\n",
              " '',\n",
              " '',\n",
              " 'Africa’s',\n",
              " 'youth',\n",
              " 'are',\n",
              " 'at',\n",
              " 'the',\n",
              " 'heart',\n",
              " 'of',\n",
              " 'the',\n",
              " 'AIMS',\n",
              " 'innovation',\n",
              " 'and',\n",
              " 'transformation',\n",
              " 'ecosystem',\n",
              " 'which',\n",
              " 'consists',\n",
              " 'of',\n",
              " 'a',\n",
              " 'set',\n",
              " 'of',\n",
              " 'academic',\n",
              " 'and',\n",
              " 'non-academic',\n",
              " 'programs',\n",
              " 'expertly',\n",
              " 'tailored',\n",
              " 'to',\n",
              " 'provide',\n",
              " 'AIMS',\n",
              " 'learners',\n",
              " 'with',\n",
              " 'a',\n",
              " 'unique',\n",
              " 'postgraduate',\n",
              " 'training',\n",
              " 'experience',\n",
              " 'on',\n",
              " 'the',\n",
              " 'continent',\n",
              " '',\n",
              " '',\n",
              " 'AIMS',\n",
              " 'offers',\n",
              " 'a',\n",
              " 'Master’s',\n",
              " 'in',\n",
              " 'mathematical',\n",
              " 'sciences,',\n",
              " 'including',\n",
              " 'a',\n",
              " 'co-operative',\n",
              " 'option',\n",
              " 'with',\n",
              " 'a',\n",
              " 'direct',\n",
              " 'link',\n",
              " 'to',\n",
              " 'industry,',\n",
              " 'the',\n",
              " 'African',\n",
              " 'Master’s',\n",
              " 'in',\n",
              " 'Machine',\n",
              " 'Intelligence',\n",
              " '(AMMI),',\n",
              " 'as',\n",
              " 'well',\n",
              " 'as',\n",
              " 'research',\n",
              " 'programs,',\n",
              " 'with',\n",
              " 'over',\n",
              " '100',\n",
              " 'researchers',\n",
              " 'conducting',\n",
              " 'studies',\n",
              " 'across',\n",
              " 'the',\n",
              " 'network',\n",
              " '',\n",
              " 'In',\n",
              " 'addition',\n",
              " 'to',\n",
              " 'the',\n",
              " 'AIMS',\n",
              " 'Industry',\n",
              " 'Initiative',\n",
              " 'and',\n",
              " 'a',\n",
              " 'gender-responsive',\n",
              " 'Teacher',\n",
              " 'Training',\n",
              " 'Program',\n",
              " 'currently',\n",
              " 'implemented',\n",
              " 'in',\n",
              " 'Cameroon',\n",
              " 'and',\n",
              " 'Rwanda,',\n",
              " 'AIMS',\n",
              " 'equally',\n",
              " 'created',\n",
              " 'two',\n",
              " 'critical',\n",
              " 'initiatives:',\n",
              " 'Quantum',\n",
              " 'Leap',\n",
              " 'Africa,',\n",
              " 'a',\n",
              " 'think',\n",
              " 'tank',\n",
              " 'looking',\n",
              " 'into',\n",
              " 'the',\n",
              " 'coming',\n",
              " 'quantum',\n",
              " 'revolution',\n",
              " 'and',\n",
              " 'the',\n",
              " 'Next',\n",
              " 'Einstein',\n",
              " 'Forum',\n",
              " 'to',\n",
              " 'propel',\n",
              " 'Africa',\n",
              " 'on',\n",
              " 'to',\n",
              " 'the',\n",
              " 'global',\n",
              " 'scientific',\n",
              " 'stage',\n",
              " '',\n",
              " '']"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "remove_dot = rdd_file.flatMap(lambda x: x.replace(\".\", \" \").split(\" \"))\n",
        "remove_dot.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PythonRDD[10] at RDD at PythonRDD.scala:56"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#split_file = rdd_file.flatMap(lambda x : x.split())\n",
        "#split_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "#length = remove_dot.map(lambda x: count(x))\n",
        "#length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The African Institute for Mathematical Sciences (AIMS) is a pan-African network of Centres of Excellence for postgraduate training in mathematical sciences, research, and public engagement in Science, Technology, Engineering, and Mathematics. Founded in 2003 in South Africa by acclaimed physicist Prof Neil Turok and later replicated in Senegal, Ghana, Cameroon and Rwanda, AIMS is leading Africa’s socio-economic transformation through:\n",
            "\n",
            "Innovative scientific training (the development of human capital);\n",
            "\n",
            "Technological advances and cutting-edge scientific discoveries; and\n",
            "\n",
            "Public engagement for the continent’s scientific emergence.\n",
            "\n",
            "Africa’s youth are at the heart of the AIMS innovation and transformation ecosystem which consists of a set of academic and non-academic programs expertly tailored to provide AIMS learners with a unique postgraduate training experience on the continent.\n",
            "\n",
            "AIMS offers a Master’s in mathematical sciences, including a co-operative option with a direct link to industry, the African Master’s in Machine Intelligence (AMMI), as well as research programs, with over 100 researchers conducting studies across the network. In addition to the AIMS Industry Initiative and a gender-responsive Teacher Training Program currently implemented in Cameroon and Rwanda, AIMS equally created two critical initiatives: Quantum Leap Africa, a think tank looking into the coming quantum revolution and the Next Einstein Forum to propel Africa on to the global scientific stage. "
          ]
        }
      ],
      "source": [
        "!cat Datasets/WhoAreWe.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rdd = sc.parallelize(['John', 'Blanche', 'Bob', 'Ben', 'Kenny'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00028-d3078029-dd5d-4852-a84f-4fb134597c5d",
        "deepnote_cell_type": "markdown",
        "id": "4sU99s5HepLs"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Use FlatMap to clean the text from `WhoAreWe.txt`file. Lower, remove dots and split into words.\n",
        "\n",
        "### GroupBy\n",
        "\n",
        "Transformation / Wide: Group the data in the original RDD. Create pairs where the key is the output of a user function, and the value is all items for which the function yields this key.\n",
        "\n",
        "![](https://github.com/pnavaro/big-data/blob/master/notebooks/images/gdj0Ey8.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "cell_id": "00029-93936a32-6fc4-4c60-b38d-7935aa2df61f",
        "deepnote_cell_type": "code",
        "id": "vQU8RnjFepLt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('J', ['John', 'James']), ('F', ['Fred']), ('A', ['Anna'])]"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd = sc.parallelize(['John', 'Fred', 'Anna', 'James'])\n",
        "rdd = rdd.groupBy(lambda w: w[0])\n",
        "[(k, list(v)) for (k, v) in rdd.collect()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00030-dd9efd67-bc72-4eb5-9e07-0a94bd233e13",
        "deepnote_cell_type": "markdown",
        "id": "EpVZpTifepLw"
      },
      "source": [
        "### GroupByKey\n",
        "\n",
        "Transformation / Wide: Group the values for each key in the original RDD. Create a new pair where the original key corresponds to this collected group of values.\n",
        "\n",
        "![](https://github.com/pnavaro/big-data/blob/master/notebooks/images/TlWRGr2.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "cell_id": "00031-bc1d6a4c-8103-42a9-a39a-ee8d80680447",
        "deepnote_cell_type": "code",
        "id": "NvrOK-EfepLx"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('B', [5, 4]), ('A', [3, 2, 1])]"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd = sc.parallelize([('B',5),('B',4),('A',3),('A',2),('A',1)])\n",
        "rdd = rdd.groupByKey()\n",
        "[(j[0], list(j[1])) for j in rdd.collect()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00032-6cff9fda-3f13-4b2b-9b2e-580ad83ecf5f",
        "deepnote_cell_type": "markdown",
        "id": "i0faKW-2epLy"
      },
      "source": [
        "### Join\n",
        "\n",
        "Transformation / Wide: Return a new RDD containing all pairs of elements having the same key in the original RDDs\n",
        "\n",
        "![](https://github.com/pnavaro/big-data/blob/master/notebooks/images/YXL42Nl.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "cell_id": "00033-10e3b4f2-3f6f-4a99-adac-d8bc8c92c2e9",
        "deepnote_cell_type": "code",
        "id": "MOTp4gfyepLy"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('a', (1, 3)), ('a', (1, 4)), ('b', (2, 5))]"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = sc.parallelize([(\"a\", 1), (\"b\", 2)])\n",
        "y = sc.parallelize([(\"a\", 3), (\"a\", 4), (\"b\", 5)])\n",
        "x.join(y).collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00034-7746caa4-cfd5-4206-b12d-f0fe01d65803",
        "deepnote_cell_type": "markdown",
        "id": "DdUCiAKaepLy"
      },
      "source": [
        "### Distinct\n",
        "\n",
        "Transformation / Wide: Return a new RDD containing distinct items from the original RDD (omitting all duplicates)\n",
        "\n",
        "![](https://github.com/pnavaro/big-data/blob/master/notebooks/images/Vqgy2a4.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "cell_id": "00035-fd077e6b-1166-4fca-b5e8-c9a310dc59e7",
        "deepnote_cell_type": "code",
        "id": "0NNxYCztepLz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[4, 1, 2, 3]"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd = sc.parallelize([1,2,3,3,4])\n",
        "rdd.distinct().collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00036-fdbf2aa3-158f-44a2-82a3-fab846eb5ab7",
        "deepnote_cell_type": "markdown",
        "id": "e8M_1HLdepLz"
      },
      "source": [
        "### KeyBy\n",
        "\n",
        "Transformation / Narrow: Create a Pair RDD, forming one pair for each item in the original RDD. The pair’s key is calculated from the value via a user-supplied function.\n",
        "\n",
        "![](https://github.com/pnavaro/big-data/blob/master/notebooks/images/nqYhDW5.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "cell_id": "00037-e13e8ce6-ad59-4cb9-a672-336afba96873",
        "deepnote_cell_type": "code",
        "id": "s9tftIZBepL1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('J', 'John'), ('F', 'Fred'), ('A', 'Anna'), ('J', 'James')]"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd = sc.parallelize(['John', 'Fred', 'Anna', 'James'])\n",
        "rdd.keyBy(lambda w: w[0]).collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00038-ee1a58a6-954d-4994-a48a-d5a98ac09051",
        "deepnote_cell_type": "markdown",
        "id": "1ifNoE7_epL1"
      },
      "source": [
        "## Actions\n",
        "\n",
        "### Map-Reduce operation\n",
        "\n",
        "Action / To Driver: Aggregate all the elements of the RDD by applying a user function pairwise to elements and partial results, and return a result to the driver\n",
        "\n",
        "![](https://github.com/pnavaro/big-data/blob/master/notebooks/images/R72uzwX.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "cell_id": "00039-cc090acd-104b-4683-844f-153af8f2956d",
        "deepnote_cell_type": "code",
        "id": "nzUdmWNnepL1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7]"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from operator import add\n",
        "rdd = sc.parallelize(list(range(8)))\n",
        "rdd.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd.map(lambda x: x ** 2).reduce(add) # reduce is an action!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00040-a9e8e4e8-143f-403e-b11c-67b97832198b",
        "deepnote_cell_type": "markdown",
        "id": "xcj6X47cepMG"
      },
      "source": [
        "### Max, Min, Sum, Mean, Variance, Stdev\n",
        "\n",
        "Action / To Driver: Compute the respective function (maximum value, minimum value, sum, mean, variance, or standard deviation) from a numeric RDD\n",
        "\n",
        "![](https://github.com/pnavaro/big-data/blob/master/notebooks/images/HUCtib1.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00041-e22cf358-c375-48c8-ba0b-5489d848df67",
        "deepnote_cell_type": "markdown",
        "id": "UkrD7-hEepMH"
      },
      "source": [
        "### CountByKey\n",
        "\n",
        "Action / To Driver: Return a map of keys and counts of their occurrences in the RDD\n",
        "\n",
        "![](https://github.com/pnavaro/big-data/blob/master/notebooks/images/jvQTGv6.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "cell_id": "00042-613102f2-fea1-436a-a695-8169201af599",
        "deepnote_cell_type": "code",
        "id": "A8c89PSyepMH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(int, {'J': 2, 'F': 1, 'A': 1})"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd = sc.parallelize([('J', 'James'), ('F','Fred'),\n",
        "                    ('A','Anna'), ('J','John')])\n",
        "\n",
        "rdd.countByKey()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "cell_id": "00043-a8624fda-21b4-4d84-b41a-0b2f94951a4a",
        "deepnote_cell_type": "code",
        "id": "HedOqxQpepML"
      },
      "outputs": [],
      "source": [
        "# Stop the local spark cluster\n",
        "sc.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00044-36e25a83-4df8-4b26-b143-ac3cf849110a",
        "deepnote_cell_type": "markdown",
        "id": "TFQwil49epML"
      },
      "source": [
        "### Exercise: Word-count in Apache Spark\n",
        "\n",
        "- Write the sample text file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "53ba4a86-7d9e-483d-acb5-582d7555be2b",
    "jupytext": {
      "text_representation": {
        "extension": ".md",
        "format_name": "myst",
        "format_version": "0.9",
        "jupytext_version": "1.5.2"
      }
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "source_map": [
      13,
      19,
      26,
      33,
      45,
      54,
      62,
      85,
      105,
      113,
      124,
      134,
      143,
      148,
      153,
      160,
      162,
      166,
      170,
      176,
      183,
      197,
      207,
      210,
      216,
      225,
      228,
      236,
      239,
      251,
      255,
      263,
      267,
      275,
      279,
      287,
      290,
      298,
      301,
      311,
      315,
      323,
      331,
      338,
      341,
      347,
      351,
      392,
      398,
      402,
      407,
      413,
      428,
      439,
      443,
      459,
      463,
      467,
      473,
      477,
      493,
      499,
      503,
      509,
      513,
      525
    ]
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
